{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMP6mrQTYn6tvcSd765r7xZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsung-chow/324-Project/blob/main/XGBOOST_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vLUEN4SnjMLe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as torch_data\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnE4gAa6jZN3",
        "outputId": "9588a5a3-5663-4dc2-f848-542560273852"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load data\n",
        "use_cols_games = ['gameId', 'hometeamId', 'awayteamId', 'winner']\n",
        "games_df = pd.read_csv('/content/drive/MyDrive/nba/Games.csv', usecols=use_cols_games, low_memory=False, nrows=50000)\n",
        "\n",
        "use_cols_stats = ['teamId', 'seasonWins', 'seasonLosses']\n",
        "team_stats_df = pd.read_csv('/content/drive/MyDrive/nba/TeamStatistics.csv', usecols=use_cols_stats, low_memory=False, nrows=50000)\n",
        "\n",
        "use_cols_player_stats = ['personId', 'points', 'assists', 'reboundsTotal']\n",
        "player_stats_df = pd.read_csv('/content/drive/MyDrive/nba/PlayerStatistics.csv', usecols=use_cols_player_stats, low_memory=False, nrows=50000)\n",
        "\n",
        "# Handle missing values\n",
        "games_df.fillna({'hometeamId': -1, 'awayteamId': -1, 'winner': -1}, inplace=True)\n",
        "team_stats_df.fillna({'teamId': -1, 'seasonWins': 0, 'seasonLosses': 1}, inplace=True)\n",
        "player_stats_df.fillna(0, inplace=True)\n",
        "\n",
        "# Convert data types\n",
        "games_df[['hometeamId', 'awayteamId', 'winner']] = games_df[['hometeamId', 'awayteamId', 'winner']].astype('int32')\n",
        "team_stats_df[['teamId', 'seasonWins', 'seasonLosses']] = team_stats_df[['teamId', 'seasonWins', 'seasonLosses']].astype('int16')\n",
        "\n",
        "# Compute Home Team Win Indicator\n",
        "games_df['HomeTeamWins'] = (games_df['winner'] == games_df['hometeamId']).astype(int)\n",
        "\n",
        "# Merge additional data\n",
        "team_stats_df['WinPct'] = team_stats_df['seasonWins'] / (team_stats_df['seasonWins'] + team_stats_df['seasonLosses'])\n",
        "\n",
        "# Aggregate player statistics per team\n",
        "player_avg_stats = player_stats_df.groupby('personId')[['points', 'assists', 'reboundsTotal']].mean().reset_index()\n",
        "\n",
        "# Merge team statistics\n",
        "games_df = games_df.merge(team_stats_df[['teamId', 'WinPct', 'seasonWins', 'seasonLosses']], left_on='hometeamId', right_on='teamId', how='left')\n",
        "games_df.rename(columns={'WinPct': 'WinPct_home', 'seasonWins': 'seasonWins_home', 'seasonLosses': 'seasonLosses_home'}, inplace=True)\n",
        "games_df.drop(columns=['teamId'], inplace=True)\n",
        "\n",
        "games_df = games_df.merge(team_stats_df[['teamId', 'WinPct', 'seasonWins', 'seasonLosses']], left_on='awayteamId', right_on='teamId', how='left')\n",
        "games_df.rename(columns={'WinPct': 'WinPct_away', 'seasonWins': 'seasonWins_away', 'seasonLosses': 'seasonLosses_away'}, inplace=True)\n",
        "games_df.drop(columns=['teamId'], inplace=True)\n",
        "\n",
        "# Selecting features\n",
        "games_df.fillna(0, inplace=True)\n",
        "games_df['WinPct_Diff'] = games_df['WinPct_home'] - games_df['WinPct_away']\n",
        "games_df['RecentPerformance'] = games_df['WinPct_home'] * 0.6 + games_df['WinPct_away'] * 0.4\n",
        "games_df['seasonWinRate_home'] = games_df['seasonWins_home'] / (games_df['seasonWins_home'] + games_df['seasonLosses_home'] + 1)\n",
        "games_df['seasonWinRate_away'] = games_df['seasonWins_away'] / (games_df['seasonWins_away'] + games_df['seasonLosses_away'] + 1)\n",
        "\n",
        "games_df['AvgPlayerPoints'] = player_avg_stats['points'].mean()\n",
        "games_df['AvgPlayerAssists'] = player_avg_stats['assists'].mean()\n",
        "games_df['AvgPlayerRebounds'] = player_avg_stats['reboundsTotal'].mean()\n",
        "\n",
        "X = games_df[['WinPct_Diff', 'RecentPerformance', 'seasonWinRate_home', 'seasonWinRate_away', 'AvgPlayerPoints', 'AvgPlayerAssists', 'AvgPlayerRebounds']]\n",
        "y = games_df['HomeTeamWins']\n",
        "\n",
        "# Convert DataFrame to numpy arrays\n",
        "X_numpy = X.to_numpy()\n",
        "y_numpy = y.to_numpy()\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_numpy), y=y_numpy)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_numpy, y_numpy, test_size=0.2, random_state=42, stratify=y_numpy)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "A8-LO6IOjhsQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Compute class distribution\n",
        "unique, counts = np.unique(y_numpy, return_counts=True)\n",
        "# Print class distribution\n",
        "print(\"Class Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Class {label}: {count} samples ({count / len(y_numpy) * 100:.2f}%)\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0nzkmNWjx-q",
        "outputId": "76f8b69c-4770-462a-9482-887b3c4ea45e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "Class 0: 19943 samples (39.89%)\n",
            "Class 1: 30057 samples (60.11%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print sample input and output\n",
        "num_input_features = X.shape[1]\n",
        "print(f\"Number of input parameters: {num_input_features}\")\n",
        "print(\"Input feature labels: [WinPct_Diff, RecentPerformance, seasonWinRate_home, seasonWinRate_away, AvgPlayerPoints, AvgPlayerAssists, AvgPlayerRebounds]\")\n",
        "print(\"Sample input (features):\", X_numpy[0])\n",
        "print(\"Sample output (label):\", y_numpy[0])\n",
        "print(\"Output label 1 -> home team won, 0 -> away team won.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HB1HJGlj8V0",
        "outputId": "62ded58e-fcd9-4e9e-fc39-2f7bd2536b19"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of input parameters: 7\n",
            "Input feature labels: [WinPct_Diff, RecentPerformance, seasonWinRate_home, seasonWinRate_away, AvgPlayerPoints, AvgPlayerAssists, AvgPlayerRebounds]\n",
            "Sample input (features): [0.         0.         0.         0.         6.32532707 1.50569392\n",
            " 2.56189076]\n",
            "Sample output (label): 0\n",
            "Output label 1 -> home team won, 0 -> away team won.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "# Convert to DMatrix\n",
        "dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
        "dval = xgb.DMatrix(X_val, label=y_val)\n",
        "\n",
        "params = {\n",
        "    'objective': 'binary:logistic',\n",
        "    'eval_metric': 'logloss',\n",
        "    'eta': 0.1,\n",
        "    'max_depth': 6,\n",
        "    'subsample': 0.8,\n",
        "    'colsample_bytree': 0.8,\n",
        "    'tree_method': 'gpu_hist' if device == 'cuda' else 'auto',\n",
        "}\n",
        "\n",
        "# Simulate epoch-like training\n",
        "num_epochs = 20\n",
        "model = None\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    model = xgb.train(params, dtrain, num_boost_round=1, xgb_model=model)\n",
        "\n",
        "    # Predictions\n",
        "    y_train_pred = model.predict(dtrain)\n",
        "    y_val_pred = model.predict(dval)\n",
        "\n",
        "    # Compute loss and accuracy\n",
        "    train_loss = log_loss(y_tr, y_train_pred)\n",
        "    val_loss = log_loss(y_val, y_val_pred)\n",
        "\n",
        "    train_acc = accuracy_score(y_tr, (y_train_pred >= 0.5).astype(int)) * 100\n",
        "    val_acc = accuracy_score(y_val, (y_val_pred >= 0.5).astype(int)) * 100\n",
        "\n",
        "    # Pretty print\n",
        "    print(f\"Epoch {epoch:2d}/{num_epochs} | \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
        "          f\"Test Loss: {val_loss:.4f} | Test Acc: {val_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwsvEnTLkM66",
        "outputId": "ee68a570-5f4c-40df-df63-3d40c325001e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch  2/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch  3/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch  4/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch  5/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch  6/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch  7/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch  8/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch  9/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 10/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 11/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 12/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 13/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 14/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 15/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 16/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 17/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 18/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 19/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n",
            "Epoch 20/20 | Train Loss: 0.6728 | Train Acc: 60.06% | Test Loss: 0.6717 | Test Acc: 60.32%\n"
          ]
        }
      ]
    }
  ]
}
