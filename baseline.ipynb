{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOyDOY5PWGd1A/fp9rKxNzW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsung-chow/324-Project/blob/main/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as torch_data\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "gm2U22rycXPP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VViul560ebWg",
        "outputId": "61c6bef8-5b99-4624-bd02-6cfd1b7e4719"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "use_cols_games = ['gameId', 'hometeamId', 'awayteamId', 'winner']\n",
        "games_df = pd.read_csv('/content/drive/MyDrive/nba/Games.csv', usecols=use_cols_games, low_memory=False, nrows=50000)\n",
        "\n",
        "use_cols_stats = ['teamId', 'seasonWins', 'seasonLosses']\n",
        "team_stats_df = pd.read_csv('/content/drive/MyDrive/nba/TeamStatistics.csv', usecols=use_cols_stats, low_memory=False, nrows=50000)\n",
        "\n",
        "use_cols_player_stats = ['personId', 'points', 'assists', 'reboundsTotal']\n",
        "player_stats_df = pd.read_csv('/content/drive/MyDrive/nba/PlayerStatistics.csv', usecols=use_cols_player_stats, low_memory=False, nrows=50000)\n",
        "\n",
        "# Handle missing values\n",
        "games_df.fillna({'hometeamId': -1, 'awayteamId': -1, 'winner': -1}, inplace=True)\n",
        "team_stats_df.fillna({'teamId': -1, 'seasonWins': 0, 'seasonLosses': 1}, inplace=True)\n",
        "player_stats_df.fillna(0, inplace=True)\n",
        "\n",
        "# Convert data types\n",
        "games_df[['hometeamId', 'awayteamId', 'winner']] = games_df[['hometeamId', 'awayteamId', 'winner']].astype('int32')\n",
        "team_stats_df[['teamId', 'seasonWins', 'seasonLosses']] = team_stats_df[['teamId', 'seasonWins', 'seasonLosses']].astype('int16')\n",
        "\n",
        "# Compute Home Team Win Indicator\n",
        "games_df['HomeTeamWins'] = (games_df['winner'] == games_df['hometeamId']).astype(int)\n",
        "\n",
        "# Merge additional data\n",
        "team_stats_df['WinPct'] = team_stats_df['seasonWins'] / (team_stats_df['seasonWins'] + team_stats_df['seasonLosses'])\n",
        "\n",
        "# Aggregate player statistics per team\n",
        "player_avg_stats = player_stats_df.groupby('personId')[['points', 'assists', 'reboundsTotal']].mean().reset_index()\n",
        "\n",
        "# Merge team statistics\n",
        "games_df = games_df.merge(team_stats_df[['teamId', 'WinPct', 'seasonWins', 'seasonLosses']], left_on='hometeamId', right_on='teamId', how='left')\n",
        "games_df.rename(columns={'WinPct': 'WinPct_home', 'seasonWins': 'seasonWins_home', 'seasonLosses': 'seasonLosses_home'}, inplace=True)\n",
        "games_df.drop(columns=['teamId'], inplace=True)\n",
        "\n",
        "games_df = games_df.merge(team_stats_df[['teamId', 'WinPct', 'seasonWins', 'seasonLosses']], left_on='awayteamId', right_on='teamId', how='left')\n",
        "games_df.rename(columns={'WinPct': 'WinPct_away', 'seasonWins': 'seasonWins_away', 'seasonLosses': 'seasonLosses_away'}, inplace=True)\n",
        "games_df.drop(columns=['teamId'], inplace=True)\n",
        "\n",
        "# Selecting features\n",
        "games_df.fillna(0, inplace=True)\n",
        "games_df['WinPct_Diff'] = games_df['WinPct_home'] - games_df['WinPct_away']\n",
        "games_df['RecentPerformance'] = games_df['WinPct_home'] * 0.6 + games_df['WinPct_away'] * 0.4\n",
        "games_df['seasonWinRate_home'] = games_df['seasonWins_home'] / (games_df['seasonWins_home'] + games_df['seasonLosses_home'] + 1)\n",
        "games_df['seasonWinRate_away'] = games_df['seasonWins_away'] / (games_df['seasonWins_away'] + games_df['seasonLosses_away'] + 1)\n",
        "\n",
        "games_df['AvgPlayerPoints'] = player_avg_stats['points'].mean()\n",
        "games_df['AvgPlayerAssists'] = player_avg_stats['assists'].mean()\n",
        "games_df['AvgPlayerRebounds'] = player_avg_stats['reboundsTotal'].mean()\n",
        "\n",
        "X = games_df[['WinPct_Diff', 'RecentPerformance', 'seasonWinRate_home', 'seasonWinRate_away', 'AvgPlayerPoints', 'AvgPlayerAssists', 'AvgPlayerRebounds']]\n",
        "y = games_df['HomeTeamWins']\n",
        "\n",
        "# Convert DataFrame to numpy arrays\n",
        "X_numpy = X.to_numpy()\n",
        "y_numpy = y.to_numpy()\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_numpy), y=y_numpy)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_numpy, y_numpy, test_size=0.2, random_state=42, stratify=y_numpy)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "DVSCkVNJDqIv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class distribution\n",
        "unique, counts = np.unique(y_numpy, return_counts=True)\n",
        "# Print class distribution\n",
        "print(\"Class Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Class {label}: {count} samples ({count / len(y_numpy) * 100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFFgnlflQYc-",
        "outputId": "86e73203-b773-4e94-acb7-fb135180282f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "Class 0: 19929 samples (39.86%)\n",
            "Class 1: 30071 samples (60.14%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sample input and output\n",
        "num_input_features = X.shape[1]\n",
        "print(f\"Number of input parameters: {num_input_features}\")\n",
        "print(\"Input feature labels: [WinPct_Diff, RecentPerformance, seasonWinRate_home, seasonWinRate_away, AvgPlayerPoints, AvgPlayerAssists, AvgPlayerRebounds]\")\n",
        "print(\"Sample input (features):\", X_numpy[0])\n",
        "print(\"Sample output (label):\", y_numpy[0])\n",
        "print(\"Output label 1 -> home team won, 0 -> away team won.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V6WCcZyElaf",
        "outputId": "824eb7db-7297-4056-fb71-d8779bc4b3d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of input parameters: 7\n",
            "Input feature labels: [WinPct_Diff, RecentPerformance, seasonWinRate_home, seasonWinRate_away, AvgPlayerPoints, AvgPlayerAssists, AvgPlayerRebounds]\n",
            "Sample input (features): [0.         0.         0.         0.         6.31876056 1.50431959\n",
            " 2.55590807]\n",
            "Sample output (label): 0\n",
            "Output label 1 -> home team won, 0 -> away team won.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize Model\n",
        "num_input_features = X_train_tensor.shape[1]\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = MLPModel(num_input_features).to(device)\n"
      ],
      "metadata": {
        "id": "fTEl9jTgGj3p"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Focal Loss to handle class imbalance\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=0.75):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
        "        return loss.mean()\n",
        "\n",
        "# Initialize model, optimizer, and scheduler\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = MLPModel(X_train_tensor.shape[1]).to(device)  # Ensure model is defined\n",
        "\n",
        "criterion = FocalLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
        "\n",
        "# Training loop\n",
        "epochs = 20\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "epochs_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device).view(-1, 1)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Compute training accuracy\n",
        "        y_pred_class = (torch.sigmoid(y_pred) > 0.5).float()\n",
        "        correct += (y_pred_class == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "    train_accuracy = correct / total * 100\n",
        "    scheduler.step()\n",
        "    train_losses.append(train_loss)  # Store train loss\n",
        "    epochs_list.append(epoch + 1)\n",
        "\n",
        "    # Evaluation loop\n",
        "    model.eval()\n",
        "    test_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch in test_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device).view(-1, 1)\n",
        "            y_pred = model(X_batch)\n",
        "\n",
        "            # Compute test loss\n",
        "            loss = criterion(y_pred, y_batch)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Compute test accuracy\n",
        "            y_pred_class = (torch.sigmoid(y_pred) > 0.5).float()\n",
        "            correct += (y_pred_class == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    test_loss /= len(test_loader)\n",
        "    test_accuracy = correct / total * 100\n",
        "    test_losses.append(test_loss)  # Store test loss\n",
        "\n",
        "    # Print training stats\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_accuracy:.2f}% | Test Loss: {test_loss:.4f} | Test Acc: {test_accuracy:.2f}%\")\n",
        "\n",
        "# Plot training and test loss\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(epochs_list, train_losses, label=\"Train Loss\", marker=\"o\")\n",
        "plt.plot(epochs_list, test_losses, label=\"Test Loss\", marker=\"s\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training and Test Loss Over Epochs\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# **Check Prediction Distribution**\n",
        "y_pred = (torch.sigmoid(model(X_test_tensor.to(device))) > 0.5).cpu().numpy()\n",
        "unique, counts = np.unique(y_pred, return_counts=True)\n",
        "print(\"Final Prediction Distribution:\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYEnL5uj_XId",
        "outputId": "af150db2-4c56-4a57-93ff-45e3b97decc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Train Loss: 0.1278 | Train Acc: 60.14% | Test Loss: 0.1300 | Test Acc: 39.86%\n"
          ]
        }
      ]
    }
  ]
}