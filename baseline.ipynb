{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNU/ReFNgdFzK9Wu/tZDOc1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsung-chow/324-Project/blob/main/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as torch_data"
      ],
      "metadata": {
        "id": "gm2U22rycXPP"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VViul560ebWg",
        "outputId": "b7bdd0c6-c1a2-4c27-b088-af03f390bcf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "use_cols_games = ['gameId', 'hometeamId', 'awayteamId', 'winner']\n",
        "games_df = pd.read_csv('/content/drive/MyDrive/nba/Games.csv', usecols=use_cols_games, low_memory=False, nrows=50000)\n",
        "\n",
        "use_cols_stats = ['teamId', 'seasonWins', 'seasonLosses']\n",
        "team_stats_df = pd.read_csv('/content/drive/MyDrive/nba/TeamStatistics.csv', usecols=use_cols_stats, low_memory=False, nrows=50000)\n",
        "\n",
        "use_cols_player_stats = ['personId', 'points', 'assists', 'reboundsTotal']\n",
        "player_stats_df = pd.read_csv('/content/drive/MyDrive/nba/PlayerStatistics.csv', usecols=use_cols_player_stats, low_memory=False, nrows=50000)\n",
        "\n",
        "# Handle missing values\n",
        "games_df.fillna({'hometeamId': -1, 'awayteamId': -1, 'winner': -1}, inplace=True)\n",
        "team_stats_df.fillna({'teamId': -1, 'seasonWins': 0, 'seasonLosses': 1}, inplace=True)\n",
        "player_stats_df.fillna(0, inplace=True)\n",
        "\n",
        "# Convert data types\n",
        "games_df[['hometeamId', 'awayteamId', 'winner']] = games_df[['hometeamId', 'awayteamId', 'winner']].astype('int32')\n",
        "team_stats_df[['teamId', 'seasonWins', 'seasonLosses']] = team_stats_df[['teamId', 'seasonWins', 'seasonLosses']].astype('int16')\n",
        "\n",
        "# Compute Home Team Win Indicator\n",
        "games_df['HomeTeamWins'] = (games_df['winner'] == games_df['hometeamId']).astype(int)\n",
        "\n",
        "# Merge additional data\n",
        "team_stats_df['WinPct'] = team_stats_df['seasonWins'] / (team_stats_df['seasonWins'] + team_stats_df['seasonLosses'])\n",
        "\n",
        "# Aggregate player statistics per team\n",
        "player_avg_stats = player_stats_df.groupby('personId')[['points', 'assists', 'reboundsTotal']].mean().reset_index()\n",
        "\n",
        "# Merge team statistics\n",
        "games_df = games_df.merge(team_stats_df[['teamId', 'WinPct', 'seasonWins', 'seasonLosses']], left_on='hometeamId', right_on='teamId', how='left')\n",
        "games_df.rename(columns={'WinPct': 'WinPct_home', 'seasonWins': 'seasonWins_home', 'seasonLosses': 'seasonLosses_home'}, inplace=True)\n",
        "games_df.drop(columns=['teamId'], inplace=True)\n",
        "\n",
        "games_df = games_df.merge(team_stats_df[['teamId', 'WinPct', 'seasonWins', 'seasonLosses']], left_on='awayteamId', right_on='teamId', how='left')\n",
        "games_df.rename(columns={'WinPct': 'WinPct_away', 'seasonWins': 'seasonWins_away', 'seasonLosses': 'seasonLosses_away'}, inplace=True)\n",
        "games_df.drop(columns=['teamId'], inplace=True)\n",
        "\n",
        "# Selecting features\n",
        "games_df.fillna(0, inplace=True)\n",
        "games_df['WinPct_Diff'] = games_df['WinPct_home'] - games_df['WinPct_away']\n",
        "games_df['RecentPerformance'] = games_df['WinPct_home'] * 0.6 + games_df['WinPct_away'] * 0.4\n",
        "games_df['seasonWinRate_home'] = games_df['seasonWins_home'] / (games_df['seasonWins_home'] + games_df['seasonLosses_home'] + 1)\n",
        "games_df['seasonWinRate_away'] = games_df['seasonWins_away'] / (games_df['seasonWins_away'] + games_df['seasonLosses_away'] + 1)\n",
        "\n",
        "games_df['AvgPlayerPoints'] = player_avg_stats['points'].mean()\n",
        "games_df['AvgPlayerAssists'] = player_avg_stats['assists'].mean()\n",
        "games_df['AvgPlayerRebounds'] = player_avg_stats['reboundsTotal'].mean()\n",
        "\n",
        "X = games_df[['WinPct_Diff', 'RecentPerformance', 'seasonWinRate_home', 'seasonWinRate_away', 'AvgPlayerPoints', 'AvgPlayerAssists', 'AvgPlayerRebounds']]\n",
        "y = games_df['HomeTeamWins']\n",
        "\n",
        "# Convert DataFrame to numpy arrays\n",
        "X_numpy = X.to_numpy()\n",
        "y_numpy = y.to_numpy()\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y_numpy), y=y_numpy)\n",
        "class_weights = torch.tensor(class_weights, dtype=torch.float32)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_numpy, y_numpy, test_size=0.2, random_state=42, stratify=y_numpy)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n"
      ],
      "metadata": {
        "id": "DVSCkVNJDqIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class distribution\n",
        "unique, counts = np.unique(y_numpy, return_counts=True)\n",
        "# Print class distribution\n",
        "print(\"Class Distribution:\")\n",
        "for label, count in zip(unique, counts):\n",
        "    print(f\"Class {label}: {count} samples ({count / len(y_numpy) * 100:.2f}%)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFFgnlflQYc-",
        "outputId": "704812e8-b9d7-46b5-a99e-6df8ffc8dd8a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution:\n",
            "Class 0: 19929 samples (39.86%)\n",
            "Class 1: 30071 samples (60.14%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print sample input and output\n",
        "num_input_features = X.shape[1]\n",
        "print(f\"Number of input parameters: {num_input_features}\")\n",
        "print(\"Input feature labels: [WinPct_Diff, RecentPerformance, seasonWinRate_home, seasonWinRate_away, AvgPlayerPoints, AvgPlayerAssists, AvgPlayerRebounds]\")\n",
        "print(\"Sample input (features):\", X_numpy[0])\n",
        "print(\"Sample output (label):\", y_numpy[0])\n",
        "print(\"Output label 1 -> home team won, 0 -> away team won.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V6WCcZyElaf",
        "outputId": "4e5c2643-d707-4b14-ce5c-c04a566b1495"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of input parameters: 7\n",
            "Input feature labels: [WinPct_Diff, RecentPerformance, seasonWinRate_home, seasonWinRate_away, AvgPlayerPoints, AvgPlayerAssists, AvgPlayerRebounds]\n",
            "Sample input (features): [0.         0.         0.         0.         6.31876056 1.50431959\n",
            " 2.55590807]\n",
            "Sample output (label): 0\n",
            "Output label 1 -> home team won, 0 -> away team won.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLPModel(nn.Module):\n",
        "    def __init__(self, input_size):\n",
        "        super(MLPModel, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_size, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(256, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.3),\n",
        "\n",
        "            nn.Linear(128, 64),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize Model\n",
        "num_input_features = X_train_tensor.shape[1]\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = MLPModel(num_input_features).to(device)\n"
      ],
      "metadata": {
        "id": "fTEl9jTgGj3p"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Focal Loss to handle class imbalance\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=0.75):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def forward(self, inputs, targets):\n",
        "        BCE_loss = nn.BCEWithLogitsLoss(reduction='none')(inputs, targets)\n",
        "        pt = torch.exp(-BCE_loss)\n",
        "        loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
        "        return loss.mean()\n",
        "\n",
        "# Initialize optimizer and scheduler\n",
        "criterion = FocalLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.8)\n",
        "\n",
        "# Training loop\n",
        "epochs = 25\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Compute training accuracy\n",
        "        y_pred_class = (torch.sigmoid(y_pred) > 0.5).float()\n",
        "        correct += (y_pred_class == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "    train_accuracy = correct / total * 100\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print training stats\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_accuracy:.2f}%\")\n",
        "\n",
        "model.eval()\n",
        "test_loss, correct, total = 0, 0, 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "        # Compute test loss\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "        # Compute test accuracy\n",
        "        y_pred_class = (torch.sigmoid(y_pred) > 0.5).float()\n",
        "        correct += (y_pred_class == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "test_accuracy = correct / total * 100\n",
        "\n",
        "# Print final test results\n",
        "print(f\"\\n=== FINAL TEST RESULTS ===\")\n",
        "print(f\"Test Loss: {test_loss:.4f} | Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "# **Check Prediction Distribution**\n",
        "y_pred = (torch.sigmoid(model(X_test_tensor)) > 0.5).cpu().numpy()\n",
        "unique, counts = np.unique(y_pred, return_counts=True)\n",
        "print(\"Final Prediction Distribution:\", dict(zip(unique, counts)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYEnL5uj_XId",
        "outputId": "711c94a2-3d66-4a73-e320-febe45214c6b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25 | Train Loss: 0.1266 | Train Acc: 60.14%\n",
            "Epoch 2/25 | Train Loss: 0.1266 | Train Acc: 60.14%\n",
            "Epoch 3/25 | Train Loss: 0.1266 | Train Acc: 60.14%\n",
            "Epoch 4/25 | Train Loss: 0.1266 | Train Acc: 60.14%\n",
            "Epoch 5/25 | Train Loss: 0.1266 | Train Acc: 60.14%\n",
            "Epoch 6/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 7/25 | Train Loss: 0.1266 | Train Acc: 60.14%\n",
            "Epoch 8/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 9/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 10/25 | Train Loss: 0.1266 | Train Acc: 60.14%\n",
            "Epoch 11/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 12/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 13/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 14/25 | Train Loss: 0.1266 | Train Acc: 60.14%\n",
            "Epoch 15/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 16/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 17/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 18/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 19/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 20/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 21/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 22/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 23/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 24/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "Epoch 25/25 | Train Loss: 0.1265 | Train Acc: 60.14%\n",
            "\n",
            "=== FINAL TEST RESULTS ===\n",
            "Test Loss: 0.1265 | Test Accuracy: 60.14%\n",
            "Final Prediction Distribution: {True: 10000}\n"
          ]
        }
      ]
    }
  ]
}