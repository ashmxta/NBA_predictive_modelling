{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samsung-chow/324-Project/blob/main/Time_Series_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "GaA1vmakLKU9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import json\n",
        "from torch.utils.data import DataLoader , TensorDataset\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c49uekNjLObZ",
        "outputId": "932ae3c2-1642-4b69-cf16-9fd843b4bc00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "QCpvIpX91isG",
        "outputId": "3e9f4dcf-b981-48b3-8b10-13aab35553b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      team  opponent  attempted_field_goals  \\\n",
              "0       12        20                     81   \n",
              "1       12         6                     82   \n",
              "2       12        24                     84   \n",
              "3       12         9                     76   \n",
              "4       12        20                     92   \n",
              "...    ...       ...                    ...   \n",
              "8940    24        15                     80   \n",
              "8941    24        14                     87   \n",
              "8942    24        19                     89   \n",
              "8943    24        18                     78   \n",
              "8944    24         6                    100   \n",
              "\n",
              "      attempted_three_point_field_goals  attempted_free_throws  assists  \\\n",
              "0                                    30                     39       26   \n",
              "1                                    26                     25       22   \n",
              "2                                    34                     33       20   \n",
              "3                                    24                     34       17   \n",
              "4                                    28                     15       26   \n",
              "...                                 ...                    ...      ...   \n",
              "8940                                 34                     22       23   \n",
              "8941                                 30                     20       29   \n",
              "8942                                 21                     29       15   \n",
              "8943                                 27                     40       17   \n",
              "8944                                 40                     17       24   \n",
              "\n",
              "      steals  personal_fouls  avg_game_score  percent_fg_made  \\\n",
              "0          8              23       11.033333         0.518519   \n",
              "1         10              24        8.200000         0.463415   \n",
              "2          4              20        7.740000         0.404762   \n",
              "3          6              15        4.950000         0.407895   \n",
              "4          9              20        6.550000         0.413043   \n",
              "...      ...             ...             ...              ...   \n",
              "8940       7              24        7.100000         0.487500   \n",
              "8941       3              19        7.538462         0.505747   \n",
              "8942       4              22        7.730000         0.460674   \n",
              "8943       4              26        8.670000         0.461538   \n",
              "8944       6              23        7.710000         0.410000   \n",
              "\n",
              "      percent_3p_made  percent_ft_made       ORB       DRB  \\\n",
              "0            0.433333         0.717949  0.500000  0.557377   \n",
              "1            0.423077         0.880000  0.541667  0.466667   \n",
              "2            0.235294         0.848485  0.250000  0.453333   \n",
              "3            0.333333         0.647059  0.333333  0.412698   \n",
              "4            0.285714         0.466667  0.526316  0.436620   \n",
              "...               ...              ...       ...       ...   \n",
              "8940         0.382353         0.818182  0.666667  0.561404   \n",
              "8941         0.500000         0.600000  0.666667  0.532258   \n",
              "8942         0.285714         0.758621  0.666667  0.480769   \n",
              "8943         0.333333         0.900000  0.666667  0.557143   \n",
              "8944         0.375000         0.882353  0.520000  0.500000   \n",
              "\n",
              "      percent_shots_blocked      TOVR  team_win  opp_win    date  \n",
              "0                  0.016393  0.117112         1        0  140223  \n",
              "1                  0.030303  0.137681         1        0  140327  \n",
              "2                  0.031496  0.056931         0        1  140416  \n",
              "3                  0.008929  0.101594         0        1  140130  \n",
              "4                  0.020408  0.073206         0        1  131121  \n",
              "...                     ...       ...       ...      ...     ...  \n",
              "8940               0.000000  0.133165         0        1  151220  \n",
              "8941               0.030928  0.059791         1        0  150115  \n",
              "8942               0.000000  0.053946         0        1  151212  \n",
              "8943               0.028846  0.089153         1        0  160318  \n",
              "8944               0.008130  0.092319         0        1  150121  \n",
              "\n",
              "[8945 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b829b79a-4377-4d08-85e0-48695099de2f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>team</th>\n",
              "      <th>opponent</th>\n",
              "      <th>attempted_field_goals</th>\n",
              "      <th>attempted_three_point_field_goals</th>\n",
              "      <th>attempted_free_throws</th>\n",
              "      <th>assists</th>\n",
              "      <th>steals</th>\n",
              "      <th>personal_fouls</th>\n",
              "      <th>avg_game_score</th>\n",
              "      <th>percent_fg_made</th>\n",
              "      <th>percent_3p_made</th>\n",
              "      <th>percent_ft_made</th>\n",
              "      <th>ORB</th>\n",
              "      <th>DRB</th>\n",
              "      <th>percent_shots_blocked</th>\n",
              "      <th>TOVR</th>\n",
              "      <th>team_win</th>\n",
              "      <th>opp_win</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>81</td>\n",
              "      <td>30</td>\n",
              "      <td>39</td>\n",
              "      <td>26</td>\n",
              "      <td>8</td>\n",
              "      <td>23</td>\n",
              "      <td>11.033333</td>\n",
              "      <td>0.518519</td>\n",
              "      <td>0.433333</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.557377</td>\n",
              "      <td>0.016393</td>\n",
              "      <td>0.117112</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>82</td>\n",
              "      <td>26</td>\n",
              "      <td>25</td>\n",
              "      <td>22</td>\n",
              "      <td>10</td>\n",
              "      <td>24</td>\n",
              "      <td>8.200000</td>\n",
              "      <td>0.463415</td>\n",
              "      <td>0.423077</td>\n",
              "      <td>0.880000</td>\n",
              "      <td>0.541667</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.030303</td>\n",
              "      <td>0.137681</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>140327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>24</td>\n",
              "      <td>84</td>\n",
              "      <td>34</td>\n",
              "      <td>33</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>7.740000</td>\n",
              "      <td>0.404762</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.453333</td>\n",
              "      <td>0.031496</td>\n",
              "      <td>0.056931</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>140416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>76</td>\n",
              "      <td>24</td>\n",
              "      <td>34</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>4.950000</td>\n",
              "      <td>0.407895</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.412698</td>\n",
              "      <td>0.008929</td>\n",
              "      <td>0.101594</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>140130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>20</td>\n",
              "      <td>92</td>\n",
              "      <td>28</td>\n",
              "      <td>15</td>\n",
              "      <td>26</td>\n",
              "      <td>9</td>\n",
              "      <td>20</td>\n",
              "      <td>6.550000</td>\n",
              "      <td>0.413043</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.526316</td>\n",
              "      <td>0.436620</td>\n",
              "      <td>0.020408</td>\n",
              "      <td>0.073206</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>131121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8940</th>\n",
              "      <td>24</td>\n",
              "      <td>15</td>\n",
              "      <td>80</td>\n",
              "      <td>34</td>\n",
              "      <td>22</td>\n",
              "      <td>23</td>\n",
              "      <td>7</td>\n",
              "      <td>24</td>\n",
              "      <td>7.100000</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.382353</td>\n",
              "      <td>0.818182</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.561404</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.133165</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>151220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8941</th>\n",
              "      <td>24</td>\n",
              "      <td>14</td>\n",
              "      <td>87</td>\n",
              "      <td>30</td>\n",
              "      <td>20</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>7.538462</td>\n",
              "      <td>0.505747</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.532258</td>\n",
              "      <td>0.030928</td>\n",
              "      <td>0.059791</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8942</th>\n",
              "      <td>24</td>\n",
              "      <td>19</td>\n",
              "      <td>89</td>\n",
              "      <td>21</td>\n",
              "      <td>29</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>22</td>\n",
              "      <td>7.730000</td>\n",
              "      <td>0.460674</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.758621</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.480769</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053946</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>151212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8943</th>\n",
              "      <td>24</td>\n",
              "      <td>18</td>\n",
              "      <td>78</td>\n",
              "      <td>27</td>\n",
              "      <td>40</td>\n",
              "      <td>17</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>8.670000</td>\n",
              "      <td>0.461538</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.557143</td>\n",
              "      <td>0.028846</td>\n",
              "      <td>0.089153</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>160318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8944</th>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>17</td>\n",
              "      <td>24</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>7.710000</td>\n",
              "      <td>0.410000</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.008130</td>\n",
              "      <td>0.092319</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>150121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8945 rows √ó 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b829b79a-4377-4d08-85e0-48695099de2f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b829b79a-4377-4d08-85e0-48695099de2f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b829b79a-4377-4d08-85e0-48695099de2f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-43af33a9-ae96-4281-9861-240cf39d59fd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43af33a9-ae96-4281-9861-240cf39d59fd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-43af33a9-ae96-4281-9861-240cf39d59fd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8e94caa5-22ba-451d-9de9-acbd0a78b0c6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8e94caa5-22ba-451d-9de9-acbd0a78b0c6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8945,\n  \"fields\": [\n    {\n      \"column\": \"team\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 29,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          5,\n          28,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opponent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 29,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          10,\n          19,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attempted_field_goals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 61,\n        \"max\": 129,\n        \"num_unique_values\": 60,\n        \"samples\": [\n          81,\n          79,\n          74\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attempted_three_point_field_goals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 4,\n        \"max\": 63,\n        \"num_unique_values\": 56,\n        \"samples\": [\n          30,\n          15,\n          13\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attempted_free_throws\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 54,\n        \"num_unique_values\": 54,\n        \"samples\": [\n          30,\n          51,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"assists\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 6,\n        \"max\": 50,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          42,\n          9,\n          21\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"steals\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 22,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          8,\n          1,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"personal_fouls\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 4,\n        \"max\": 42,\n        \"num_unique_values\": 34,\n        \"samples\": [\n          21,\n          31,\n          33\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"avg_game_score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.9400403790562843,\n        \"min\": 2.2153846153846155,\n        \"max\": 18.46666666666667,\n        \"num_unique_values\": 3431,\n        \"samples\": [\n          6.73,\n          11.266666666666666,\n          9.788888888888888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"percent_fg_made\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0550765314738098,\n        \"min\": 0.2783505154639175,\n        \"max\": 0.6842105263157895,\n        \"num_unique_values\": 821,\n        \"samples\": [\n          0.5360824742268041,\n          0.4936708860759494,\n          0.3548387096774194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"percent_3p_made\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09205292039630666,\n        \"min\": 0.0,\n        \"max\": 0.8421052631578947,\n        \"num_unique_values\": 393,\n        \"samples\": [\n          0.32,\n          0.1578947368421052,\n          0.1612903225806451\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"percent_ft_made\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10285288050931615,\n        \"min\": 0.1764705882352941,\n        \"max\": 1.0,\n        \"num_unique_values\": 298,\n        \"samples\": [\n          0.8787878787878788,\n          0.9642857142857144,\n          0.9696969696969696\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13440506388891213,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 281,\n        \"samples\": [\n          0.4583333333333333,\n          0.8333333333333334,\n          0.3939393939393939\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DRB\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05491624480520227,\n        \"min\": 0.2307692307692307,\n        \"max\": 0.711864406779661,\n        \"num_unique_values\": 683,\n        \"samples\": [\n          0.4642857142857143,\n          0.6060606060606061,\n          0.5178571428571429\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"percent_shots_blocked\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.021178584432833773,\n        \"min\": 0.0,\n        \"max\": 0.168141592920354,\n        \"num_unique_values\": 692,\n        \"samples\": [\n          0.0319148936170212,\n          0.0135135135135135,\n          0.053030303030303\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TOVR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02844208486160873,\n        \"min\": 0.0073702830188679,\n        \"max\": 0.2213840603476549,\n        \"num_unique_values\": 6354,\n        \"samples\": [\n          0.0667913438418381,\n          0.1122754491017964,\n          0.0869216368012837\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"team_win\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"opp_win\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32506,\n        \"min\": 130111,\n        \"max\": 240519,\n        \"num_unique_values\": 1641,\n        \"samples\": [\n          170126,\n          240411\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# Load the CSV file; update the filename if needed\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/nba/cleaned_data_with_dates.CSV\")\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "IB4XxYDWL9Jj"
      },
      "outputs": [],
      "source": [
        "df = df.sort_values(by=\"date\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "Ur7-h7k4MDtI",
        "outputId": "694dd597-b021-496b-df73-f68bc7687c1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7442    1\n",
              "1915    1\n",
              "3056    0\n",
              "19      1\n",
              "5601    1\n",
              "       ..\n",
              "4306    1\n",
              "4330    1\n",
              "8423    0\n",
              "6008    1\n",
              "3527    0\n",
              "Name: team_win, Length: 8945, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>team_win</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7442</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1915</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3056</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5601</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4306</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4330</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8423</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6008</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3527</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8945 rows √ó 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "target_column = [\n",
        "    'attempted_field_goals',\n",
        "    'attempted_three_point_field_goals',\n",
        "    'attempted_free_throws',\n",
        "    'assists',\n",
        "    'steals',\n",
        "    'personal_fouls',\n",
        "    'avg_game_score',\n",
        "    'percent_fg_made',\n",
        "    'percent_3p_made',\n",
        "\n",
        "    'percent_ft_made',\n",
        "    'ORB',\n",
        "    'DRB',\n",
        "    'percent_shots_blocked',\n",
        "    'TOVR'\n",
        "]\n",
        "\n",
        "# Inputs\n",
        "X= df[target_column]\n",
        "# Outputs\n",
        "y = df['team_win']\n",
        "scaler = StandardScaler()\n",
        "training_data = scaler.fit_transform(X)\n",
        "\n",
        "training_data.shape[0]\n",
        "\n",
        "y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "JwTv0_Q3KX5P"
      },
      "outputs": [],
      "source": [
        "X_tensor = torch.tensor(training_data, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
        "\n",
        "# Reshape X for 1D CNN: (batch_size, channels=1, sequence_length=14)\n",
        "X_tensor = X_tensor.unsqueeze(1)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create datasets and loaders\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOYyolL3gLtp"
      },
      "outputs": [],
      "source": [
        "class CNN1D(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN1D, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 3, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)  # raw logits\n",
        "        return x\n",
        "\n",
        "\n",
        "model = CNN1D()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGePb4Q1MO_v",
        "outputId": "1ce2a805-350c-4c8a-de45-d1002506889c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 239.5657\n",
            "Epoch 2, Loss: 211.9772\n",
            "Epoch 3, Loss: 196.0227\n",
            "Epoch 4, Loss: 188.1271\n",
            "Epoch 5, Loss: 181.3063\n",
            "Epoch 6, Loss: 178.8973\n",
            "Epoch 7, Loss: 175.0303\n",
            "Epoch 8, Loss: 174.2920\n",
            "Epoch 9, Loss: 170.2745\n",
            "Epoch 10, Loss: 169.6323\n",
            "Epoch 11, Loss: 166.7718\n",
            "Epoch 12, Loss: 164.7178\n",
            "Epoch 13, Loss: 162.7003\n",
            "Epoch 14, Loss: 160.3758\n",
            "Epoch 15, Loss: 158.7719\n",
            "Epoch 16, Loss: 160.2392\n",
            "Epoch 17, Loss: 157.6658\n",
            "Epoch 18, Loss: 159.3346\n",
            "Epoch 19, Loss: 156.3837\n",
            "Epoch 20, Loss: 154.3897\n",
            "‚úÖ Test Accuracy: 0.8262\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "for epoch in range(1, 21):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X).squeeze()\n",
        "\n",
        "\n",
        "        if torch.isnan(outputs).any():\n",
        "\n",
        "            continue\n",
        "\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(X_test).squeeze()\n",
        "    probs = torch.sigmoid(logits)\n",
        "    preds = (probs > 0.5).float()\n",
        "    accuracy = (preds == y_test).float().mean()\n",
        "    print(f\"‚úÖ Test Accuracy: {accuracy:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2JqqtmEhge_",
        "outputId": "a95cdedb-b707-435d-9aa6-60aee50be935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Accuracy: 0.8261598658468418\n",
            "\n",
            "üìä Confusion Matrix:\n",
            " [[789 135]\n",
            " [176 689]]\n",
            "\n",
            "üìù Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "         0.0      0.818     0.854     0.835       924\n",
            "         1.0      0.836     0.797     0.816       865\n",
            "\n",
            "    accuracy                          0.826      1789\n",
            "   macro avg      0.827     0.825     0.826      1789\n",
            "weighted avg      0.827     0.826     0.826      1789\n",
            "\n"
          ]
        }
      ],
      "source": [
        "y_true = y_test.cpu().numpy()\n",
        "y_pred = preds.cpu().numpy()\n",
        "\n",
        "# Evaluation metrics\n",
        "print(\"‚úÖ Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "print(\"\\nüìä Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
        "print(\"\\nüìù Classification Report:\\n\", classification_report(y_true, y_pred, digits=3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "26WOPOp1h6Ex",
        "outputId": "d82e603c-7569-4e66-f17f-1d8d39febb1a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGGCAYAAABhf2unAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAPnJJREFUeJzt3XlcVXX+x/H3BeGKyCImIFOipaG4pKIpWa4kGZombmWKS5s/NBU1Y6ZMLaVssayMakwdSysrrTRT1NRKXKIs0zS3otILuACKCgjn94fjnW64cBHBe+/rOY/zeMT3fM8538OMzdvP+X7PMRmGYQgAAMABuVX2AAAAAMqKIAMAABwWQQYAADgsggwAAHBYBBkAAOCwCDIAAMBhEWQAAIDDIsgAAACHRZABAAAOiyADXEX27Nmjrl27ys/PTyaTSUuXLi3X8//6668ymUyaN29euZ7XkXXs2FEdO3as7GEAKCOCDPA3+/bt00MPPaTrr79eVatWla+vr9q1a6eXX35Zp06duqLXjouL0/bt2zVt2jQtWLBArVq1uqLXq0hDhgyRyWSSr6/veX+Pe/bskclkkslk0vPPP2/3+Q8ePKjJkydr27Zt5TBaAI6iSmUPALiaLF++XH379pXZbNbgwYPVpEkTFRQU6Ouvv9aECRO0Y8cOvfnmm1fk2qdOnVJqaqr+9a9/aeTIkVfkGqGhoTp16pQ8PDyuyPkvpUqVKjp58qQ+++wz9evXz2bfu+++q6pVq+r06dNlOvfBgwc1ZcoU1a1bV82bNy/1catWrSrT9QBcHQgywH8dOHBAAwYMUGhoqNauXavatWtb98XHx2vv3r1avnz5Fbt+VlaWJMnf3/+KXcNkMqlq1apX7PyXYjab1a5dOy1atKhEkFm4cKFiYmL00UcfVchYTp48qWrVqsnT07NCrgfgyuDREvBfM2bM0IkTJzRnzhybEHNO/fr1NXr0aOvPZ86c0VNPPaUbbrhBZrNZdevW1T//+U/l5+fbHFe3bl11795dX3/9tW6++WZVrVpV119/vf7zn/9Y+0yePFmhoaGSpAkTJshkMqlu3bqSzj6SOffPfzV58mSZTCabtpSUFN16663y9/dX9erVFRYWpn/+85/W/ReaI7N27Vrddttt8vb2lr+/v3r27Kmff/75vNfbu3evhgwZIn9/f/n5+Wno0KE6efLkhX+xf3PvvfdqxYoVys7OtrZt3bpVe/bs0b333lui/9GjRzV+/Hg1bdpU1atXl6+vr7p166YffvjB2mfdunVq3bq1JGno0KHWR1Tn7rNjx45q0qSJ0tLS1L59e1WrVs36e/n7HJm4uDhVrVq1xP1HR0erRo0aOnjwYKnvFcCVR5AB/uuzzz7T9ddfr1tuuaVU/e+//35NmjRJLVu21MyZM9WhQwclJSVpwIABJfru3btXffr00e23364XXnhBNWrU0JAhQ7Rjxw5JUu/evTVz5kxJ0j333KMFCxbopZdesmv8O3bsUPfu3ZWfn6+pU6fqhRde0F133aVvvvnmosetXr1a0dHRyszM1OTJk5WQkKCNGzeqXbt2+vXXX0v079evn44fP66kpCT169dP8+bN05QpU0o9zt69e8tkMunjjz+2ti1cuFANGzZUy5YtS/Tfv3+/li5dqu7du+vFF1/UhAkTtH37dnXo0MEaKho1aqSpU6dKkh588EEtWLBACxYsUPv27a3nOXLkiLp166bmzZvrpZdeUqdOnc47vpdfflm1atVSXFycioqKJElvvPGGVq1apVdeeUUhISGlvlcAFcAAYOTk5BiSjJ49e5aq/7Zt2wxJxv3332/TPn78eEOSsXbtWmtbaGioIcnYsGGDtS0zM9Mwm83GuHHjrG0HDhwwJBnPPfeczTnj4uKM0NDQEmN48sknjb/+EZ45c6YhycjKyrrguM9dY+7cuda25s2bG4GBgcaRI0esbT/88IPh5uZmDB48uMT1hg0bZnPOu+++26hZs+YFr/nX+/D29jYMwzD69OljdOnSxTAMwygqKjKCg4ONKVOmnPd3cPr0aaOoqKjEfZjNZmPq1KnWtq1bt5a4t3M6dOhgSDKSk5PPu69Dhw42bStXrjQkGU8//bSxf/9+o3r16kavXr0ueY8AKh4VGUBSbm6uJMnHx6dU/T///HNJUkJCgk37uHHjJKnEXJrw8HDddttt1p9r1aqlsLAw7d+/v8xj/rtzc2s++eQTFRcXl+qYQ4cOadu2bRoyZIgCAgKs7c2aNdPtt99uvc+/evjhh21+vu2223TkyBHr77A07r33Xq1bt04Wi0Vr166VxWI572Ml6ey8Gje3s/+qKioq0pEjR6yPzb777rtSX9NsNmvo0KGl6tu1a1c99NBDmjp1qnr37q2qVavqjTfeKPW1AFQcggwgydfXV5J0/PjxUvX/7bff5Obmpvr169u0BwcHy9/fX7/99ptNe506dUqco0aNGjp27FgZR1xS//791a5dO91///0KCgrSgAED9MEHH1w01JwbZ1hYWIl9jRo10uHDh5WXl2fT/vd7qVGjhiTZdS933nmnfHx89P777+vdd99V69atS/wuzykuLtbMmTPVoEEDmc1mXXPNNapVq5Z+/PFH5eTklPqa//jHP+ya2Pv8888rICBA27Zt06xZsxQYGFjqYwFUHIIMoLNBJiQkRD/99JNdx/19su2FuLu7n7fdMIwyX+Pc/I1zvLy8tGHDBq1evVqDBg3Sjz/+qP79++v2228v0fdyXM69nGM2m9W7d2/Nnz9fS5YsuWA1RpKmT5+uhIQEtW/fXu+8845WrlyplJQUNW7cuNSVJ+ns78ce33//vTIzMyVJ27dvt+tYABWHIAP8V/fu3bVv3z6lpqZesm9oaKiKi4u1Z88em/aMjAxlZ2dbVyCVhxo1atis8Dnn71UfSXJzc1OXLl304osvaufOnZo2bZrWrl2rL7/88rznPjfO3bt3l9i3a9cuXXPNNfL29r68G7iAe++9V99//72OHz9+3gnS53z44Yfq1KmT5syZowEDBqhr166Kiooq8Tspbagsjby8PA0dOlTh4eF68MEHNWPGDG3durXczg+g/BBkgP969NFH5e3trfvvv18ZGRkl9u/bt08vv/yypLOPRiSVWFn04osvSpJiYmLKbVw33HCDcnJy9OOPP1rbDh06pCVLltj0O3r0aIljz70Y7u9Lws+pXbu2mjdvrvnz59sEg59++kmrVq2y3ueV0KlTJz311FN69dVXFRwcfMF+7u7uJao9ixcv1p9//mnTdi5wnS/02WvixIlKT0/X/Pnz9eKLL6pu3bqKi4u74O8RQOXhhXjAf91www1auHCh+vfvr0aNGtm82Xfjxo1avHixhgwZIkm66aabFBcXpzfffFPZ2dnq0KGDtmzZovnz56tXr14XXNpbFgMGDNDEiRN1991365FHHtHJkyf1+uuv68Ybb7SZ7Dp16lRt2LBBMTExCg0NVWZmpmbPnq1rr71Wt9566wXP/9xzz6lbt26KjIzU8OHDderUKb3yyivy8/PT5MmTy+0+/s7NzU2PP/74Jft1795dU6dO1dChQ3XLLbdo+/btevfdd3X99dfb9Lvhhhvk7++v5ORk+fj4yNvbW23atFG9evXsGtfatWs1e/ZsPfnkk9bl4HPnzlXHjh31xBNPaMaMGXadD8AVVsmrpoCrzi+//GI88MADRt26dQ1PT0/Dx8fHaNeunfHKK68Yp0+ftvYrLCw0pkyZYtSrV8/w8PAwrrvuOiMxMdGmj2GcXX4dExNT4jp/X/Z7oeXXhmEYq1atMpo0aWJ4enoaYWFhxjvvvFNi+fWaNWuMnj17GiEhIYanp6cREhJi3HPPPcYvv/xS4hp/X6K8evVqo127doaXl5fh6+tr9OjRw9i5c6dNn3PX+/vy7rlz5xqSjAMHDlzwd2oYtsuvL+RCy6/HjRtn1K5d2/Dy8jLatWtnpKamnnfZ9CeffGKEh4cbVapUsbnPDh06GI0bNz7vNf96ntzcXCM0NNRo2bKlUVhYaNNv7Nixhpubm5GamnrRewBQsUyGYccMPQAAgKsIc2QAAIDDIsgAAACHRZABAAAOiyADAAAcFkEGAAA4LIIMAABwWAQZAADgsJzyzb5eLUZW9hAAp3Bs66uVPQTAKVStoP+3vZz//zv1vWP+eaciAwAAHJZTVmQAAHBJJterTxBkAABwFiZTZY+gwhFkAABwFlRkAACAw6IiAwAAHBYVGQAA4LBcsCLjetENAAA4DSoyAAA4Cx4tAQAAh+WCj5YIMgAAOAsqMgAAwGFRkQEAAA7LBSsyrnfHAADAaVCRAQDAWfBoCQAAOCwXfLREkAEAwFkQZAAAgMNy49ESAABwVC5YkXG9OwYAAE6DigwAAM6CVUsAAMBhueCjJYIMAADOgooMAABwWFRkAACAw6IiAwAAHJYLVmRc744BAIDToCIDAICz4NESAABwWC74aIkgAwCAs6AiAwAAHBYVGQAA4LBcMMi43h0DAACnQUUGAABnwRwZAADgsFzw0RJBBgAAZ+GCFRnXi24AADgrk1vZNzvUrVtXJpOpxBYfHy9JOn36tOLj41WzZk1Vr15dsbGxysjIsDlHenq6YmJiVK1aNQUGBmrChAk6c+aM3bdMkAEAwFmYTGXf7LB161YdOnTIuqWkpEiS+vbtK0kaO3asPvvsMy1evFjr16/XwYMH1bt3b+vxRUVFiomJUUFBgTZu3Kj58+dr3rx5mjRpkv23bBiGYfdRVzmvFiMrewiAUzi29dXKHgLgFKpW0EQOr95zynzsqY+Hl/nYMWPGaNmyZdqzZ49yc3NVq1YtLVy4UH369JEk7dq1S40aNVJqaqratm2rFStWqHv37jp48KCCgoIkScnJyZo4caKysrLk6elZ6mtTkQEAwEmc73FPabeyKigo0DvvvKNhw4bJZDIpLS1NhYWFioqKsvZp2LCh6tSpo9TUVElSamqqmjZtag0xkhQdHa3c3Fzt2LHDrusz2RcAACdxOYEkPz9f+fn5Nm1ms1lms/mixy1dulTZ2dkaMmSIJMliscjT01P+/v42/YKCgmSxWKx9/hpizu0/t88eVGQAAHAWprJvSUlJ8vPzs9mSkpIueck5c+aoW7duCgkJuSK3dClUZAAAcBKXU5FJTExUQkKCTdulqjG//fabVq9erY8//tjaFhwcrIKCAmVnZ9tUZTIyMhQcHGzts2XLFptznVvVdK5PaVGRAQDASVzOHBmz2SxfX1+b7VJBZu7cuQoMDFRMTIy1LSIiQh4eHlqzZo21bffu3UpPT1dkZKQkKTIyUtu3b1dmZqa1T0pKinx9fRUeHm7XPVORAQAAdisuLtbcuXMVFxenKlX+Fyf8/Pw0fPhwJSQkKCAgQL6+vho1apQiIyPVtm1bSVLXrl0VHh6uQYMGacaMGbJYLHr88ccVHx9/yfD0dwQZAACcxOU8WrLX6tWrlZ6ermHDhpXYN3PmTLm5uSk2Nlb5+fmKjo7W7Nmzrfvd3d21bNkyjRgxQpGRkfL29lZcXJymTp1q9zh4jwyAC+I9MkD5qKj3yPjds6DMx+YsGlSOI6k4VGQAAHAWrvepJYIMAADOoiIfLV0tCDIAADgJggwAAHBYrhhkeI8MAABwWFRkAABwEq5YkSHIAADgLFwvxxBkAABwFlRkAACAwyLIAAAAh+WKQYZVSwAAwGFRkQEAwFm4XkGGIAMAgLNwxUdLBBkAAJwEQQYAADgsggwAAHBYrhhkWLUEAAAcFhUZAACchesVZAgyAAA4C1d8tESQAQDASRBkAACAwyLIAAAAx+V6OYYgg/Kxa/kUhYbULNGe/P4GjX3mAwXV9NH0MXerc9uG8vE265dfMzVjzkotXbPN2rd5w2v19OheimhcR0VFhpau2aaJL3ykvFMFFXgnQOVL+3ar5r09Rz/v/ElZWVmaOes1de4SZd3/+muv6IsVy2WxWOTh4aHw8MYaOXqsmjW7ydqn2+2ddfDgnzbnfWTMOA1/4MEKuw9UPCoyQBndet9zcnf73x+g8Poh+jx5lD5O+V6S9O+nBsvfx0t9x7yhw9kn1L9bK73z7DC1GzhDP+z+Q7Vr+Wl58ih9uOo7jX3mA/l6V9VzE2L11tRBunfCnMq6LaBSnDp1UmFhYerVO1YJo0eW2B8aWleJ/5qka6+9TqfzT+ud/8zTiAeG6bMVKQoICLD2+7+Rjyi2Tz/rz9W8vStk/EBFIsigXBw+dsLm5/FDm2hfepa+StsjSWp70/V6ZPp7+nbHb5KkZ/+9UqMGdlaL8Ov0w+4/1O22Jio8U6QxSR/IMAxJ0qhp7+vbxf/U9dddo/2/H67YGwIq0a23ddCtt3W44P47u/ew+Xn8o4la8tGH2vPLbrVpG2lt9/b21jW1al2xceLq44oVGV6Ih3LnUcVdA+5srfmfpFrbNv2wX326RqiGbzWZTCb1jY5QVXMVbfj2bNAxe1ZRYWGRNcRI0qn8s4+Ubml+Q8XeAOBACgsK9NHi9+Xj46Mbw8Js9r3977fU/pY26hfbS/Pe/rfOnDlTSaNERTGZTGXeHFWlVmQOHz6st99+W6mpqbJYLJKk4OBg3XLLLRoyZIhq8TcJh3RXp2by9/HSO59ttrbd9+jbWvDsMB1cP0OFhUU6ebpA/RPeslZa1m3ZrWcTemvs4C56deE6eXt56ulHekqSgmv5Vcp9AFez9eu+1MTxCTp9+pSuqVVLyW+9rRo1/vdY6Z6Bg9QoPFx+fn7atu17zXrpRWVlZWnCxMRKHDWuNEcOJGVVaUFm69atio6OVrVq1RQVFaUbb7xRkpSRkaFZs2bpmWee0cqVK9WqVauLnic/P1/5+fk2bUZxkUxu7lds7Li4uF63aOU3O3UoK8fa9mR8d/n7eKnbQ7N0JDtPPTo20zszhilq2Evasfegft5v0QOTFuiZcb01ddRdKiou1uxF62U5nCujuLgS7wa4OrW+uY0++GipsrOP6aMPP9CEcWP0zqLFqlnz7KT7wUOGWvveGNZQHh4eenrKkxo9dpw8PT0ra9i40lwvx1RekBk1apT69u2r5OTkEgnSMAw9/PDDGjVqlFJTUy9whrOSkpI0ZcoUmzb3oNbyqH1zuY8Zl1andg11bhOmAePfsrbVu/YajRjQQS1jn9bP+89W3rb/8qfatbxBD/Vvr0emvSdJev+Lb/X+F98qMMBHeafyZRjSI/d11oE/jlTKvQBXs2rVqqlOaKjqhIaq2U3N1aNbVy39+EMNf+Ch8/Zv2uwmnTlzRgf//EN1611fwaNFRXHFikylzZH54YcfNHbs2PP+0k0mk8aOHatt27Zd8jyJiYnKycmx2aoERVyBEaM0Bt0Vqcyjx7Xiqx3WtmpVz/7tr/gv818kqajIkNt5/vvPPHpceacK1Ce6pU4XFGrNpl1XdtCAEyg2ilVQcOFXFeze9bPc3NwUEFDyNQmAI6u0ikxwcLC2bNmihg0bnnf/li1bFBQUdMnzmM1mmc1mmzYeK1UOk8mkwT3b6t1lm1VU9L/HQbt/tWhveqZeffweJb64REdy8nRXp2bq0jZMvUcnW/s93L+9Nv2wXydOFqhL24aaPqaXnnjlE+WcOFUZtwNUmpN5eUpPT7f+/Ocff2jXzz/Lz89Pfv7++vebyerYqbOuqVVL2ceO6b1F7yozI0O3R98hSfph2/fa/uMPan1zW3l7e+uHH77Xc88mKab7XfL1Y86ZM3PFikylBZnx48frwQcfVFpamrp06WINLRkZGVqzZo3eeustPf/885U1PJRB5zZhqlM7QPOXbrJpP3OmWL1Gva6nH+mpD19+SNWrmbXv9yzdP2mBVn6909qvVZNQPf5wjKpX89TuXzM0ctoiLVq+taJvA6h0O3b8pPuHDrb+/PyMJEnSXT3v1uNPTtGBA/v16SdLlH3smPz9/dW4SVPN/c+7ql+/gSTJ09NTX6z4XMmzX1VBQYH+8Y9rNWjwEA2KG3re68F5uGCOkckw/lbvr0Dvv/++Zs6cqbS0NBUVFUmS3N3dFRERoYSEBPXr1+8SZzg/rxYlXyAFwH7Htr5a2UMAnELVCiobNJjwRZmP3fPcHeU4kopTqcuv+/fvr/79+6uwsFCHD59dhnvNNdfIw8OjMocFAIBDcsWKzFXxZl8PDw/Vrl27socBAIBDc8U5MrzZFwAAOCyCDAAATsJkKvtmrz///FP33XefatasKS8vLzVt2lTffvutdb9hGJo0aZJq164tLy8vRUVFac+ePTbnOHr0qAYOHChfX1/5+/tr+PDhOnHixN8vdVEEGQAAnISbm6nMmz2OHTumdu3aycPDQytWrNDOnTv1wgsvqEaNGtY+M2bM0KxZs5ScnKzNmzfL29tb0dHROn36tLXPwIEDtWPHDqWkpGjZsmXasGGDHnzwQbvGUqmrlq4UVi0B5YNVS0D5qKhVS43/tarMx+6Y1rXUfR977DF98803+uqrr8673zAMhYSEaNy4cRo/frwkKScnR0FBQZo3b54GDBign3/+WeHh4dq6dav1c0RffPGF7rzzTv3xxx8KCQkp1VioyAAA4CQu5+vX+fn5ys3Ntdn+/i3Dcz799FO1atVKffv2VWBgoFq0aKG33vrfp2kOHDggi8WiqKgoa5ufn5/atGlj/fRQamqq/P39bb6pGBUVJTc3N23e/L+PDl8KQQYAACdxOXNkkpKSzr49+i9bUlLSea+zf/9+vf7662rQoIFWrlypESNG6JFHHtH8+fMlSRbL2e/q/f0N/UFBQdZ9FotFgYGBNvurVKmigIAAa5/SuCqWXwMAgMqVmJiohIQEm7a/fwLonOLiYrVq1UrTp0+XJLVo0UI//fSTkpOTFRcXd8XH+ldUZAAAcBKX82jJbDbL19fXZrtQkKldu7bCw8Nt2ho1amT9RlhwcLCks58d+quMjAzrvuDgYGVmZtrsP3PmjI4ePWrtUxoEGQAAnMTlBBl7tGvXTrt377Zp++WXXxQaGipJqlevnoKDg7VmzRrr/tzcXG3evFmRkZGSpMjISGVnZystLc3aZ+3atSouLlabNm1KPRYeLQEA4CQq6sW+Y8eO1S233KLp06erX79+2rJli9588029+eab/x2HSWPGjNHTTz+tBg0aqF69enriiScUEhKiXr16STpbwbnjjjv0wAMPKDk5WYWFhRo5cqQGDBhQ6hVLEkEGAACnUVGfKGjdurWWLFmixMRETZ06VfXq1dNLL72kgQMHWvs8+uijysvL04MPPqjs7Gzdeuut+uKLL1S1alVrn3fffVcjR45Uly5d5ObmptjYWM2aNcuusfAeGQAXxHtkgPJRUe+RaTl1bZmP/W5S53IcScWhIgMAgJPgo5EAAAAOhIoMAABOwgULMgQZAACchSs+WiLIAADgJFwwxxBkAABwFlRkAACAw3LBHMOqJQAA4LioyAAA4CR4tAQAAByWC+YYggwAAM6CigwAAHBYLphjCDIAADgLV6zIsGoJAAA4LCoyAAA4CVesyBBkAABwEi6YYwgyAAA4CyoyAADAYblgjiHIAADgLKjIAAAAh+WCOYbl1wAAwHFRkQEAwEm4uWBJhiADAICTcMEcQ5ABAMBZMNkXAAA4LDfXyzEEGQAAnIUrVmRYtQQAABwWFRkAAJyECxZkCDIAADgLk1wvyRBkAABwEkz2BQAADssVJ/sSZAAAcBIumGNYtQQAABwXFRkAAJwE31oCAAAOywVzDI+WAABwFiaTqcybPSZPnlzi+IYNG1r3nz59WvHx8apZs6aqV6+u2NhYZWRk2JwjPT1dMTExqlatmgIDAzVhwgSdOXPG7numIgMAgJOoyIpM48aNtXr1auvPVar8L1KMHTtWy5cv1+LFi+Xn56eRI0eqd+/e+uabbyRJRUVFiomJUXBwsDZu3KhDhw5p8ODB8vDw0PTp0+0aB0EGAAAnUZFzZKpUqaLg4OAS7Tk5OZozZ44WLlyozp07S5Lmzp2rRo0aadOmTWrbtq1WrVqlnTt3avXq1QoKClLz5s311FNPaeLEiZo8ebI8PT1LP47SdPr0009LfcK77rqr1H0BAIBj2rNnj0JCQlS1alVFRkYqKSlJderUUVpamgoLCxUVFWXt27BhQ9WpU0epqalq27atUlNT1bRpUwUFBVn7REdHa8SIEdqxY4datGhR6nGUKsj06tWrVCczmUwqKioq9cUBAED5uZx6TH5+vvLz823azGazzGZzib5t2rTRvHnzFBYWpkOHDmnKlCm67bbb9NNPP8liscjT01P+/v42xwQFBclisUiSLBaLTYg5t//cPnuUarJvcXFxqTZCDAAAledyJvsmJSXJz8/PZktKSjrvdbp166a+ffuqWbNmio6O1ueff67s7Gx98MEHFXzHrFoCAMBpuJnKviUmJionJ8dmS0xMLNV1/f39deONN2rv3r0KDg5WQUGBsrOzbfpkZGRY59QEBweXWMV07ufzzbu5mDJN9s3Ly9P69euVnp6ugoICm32PPPJIWU4JAAAu0+V8a+lCj5FK48SJE9q3b58GDRqkiIgIeXh4aM2aNYqNjZUk7d69W+np6YqMjJQkRUZGatq0acrMzFRgYKAkKSUlRb6+vgoPD7fr2nYHme+//1533nmnTp48qby8PAUEBOjw4cPWdeAEGQAAKkdFLVoaP368evToodDQUB08eFBPPvmk3N3ddc8998jPz0/Dhw9XQkKCAgIC5Ovrq1GjRikyMlJt27aVJHXt2lXh4eEaNGiQZsyYIYvFoscff1zx8fF2hym7Hy2NHTtWPXr00LFjx+Tl5aVNmzbpt99+U0REhJ5//nl7TwcAAMpJRb0Q748//tA999yjsLAw9evXTzVr1tSmTZtUq1YtSdLMmTPVvXt3xcbGqn379goODtbHH39sPd7d3V3Lli2Tu7u7IiMjdd9992nw4MGaOnWq/fdsGIZhzwH+/v7avHmzwsLC5O/vr9TUVDVq1EibN29WXFycdu3aZfcgyptXi5GVPQTAKRzb+mplDwFwClUr6K1tgxf+WOZj/3Nvs3IcScWxuyLj4eEhN7ezhwUGBio9PV2S5Ofnp99//718RwcAAErtcib7Oiq7M2KLFi20detWNWjQQB06dNCkSZN0+PBhLViwQE2aNLkSYwQAAKVwOZN9HZXdFZnp06erdu3akqRp06apRo0aGjFihLKysvTmm2+W+wABAEDpmC5jc1R2V2RatWpl/efAwEB98cUX5TogAABQNhX5raWrBR+NBADASbhgjrE/yNSrV++iz+D2799/WQMCAAAoLbuDzJgxY2x+Liws1Pfff68vvvhCEyZMKK9xAQAAO7niZF+7g8zo0aPP2/7aa6/p22+/vewBAQCAsnHBHFN+H43s1q2bPvroo/I6HQAAsJObyVTmzVGV22TfDz/8UAEBAeV1OgAAYCcHziNlVqYX4v31GZxhGLJYLMrKytLs2bPLdXAAAKD0mCNTCj179rT5Rbm5ualWrVrq2LGjGjZsWK6DAwAAuBi7PxrpCLJOnKnsIQBOof4Diyp7CIBTyFk0qEKuM2rJz2U+9pW7G5XjSCqO3ZN93d3dlZmZWaL9yJEjcnd3L5dBAQAA+5lMpjJvjsruR0sXKuDk5+fL09PzsgcEAADKxpG/Yl1WpQ4ys2bNknQ27f373/9W9erVrfuKioq0YcMG5sgAAFCJCDIXMXPmTElnKzLJyck2j5E8PT1Vt25dJScnl/8IAQBAqTjyI6KyKnWQOXDggCSpU6dO+vjjj1WjRo0rNigAAGA/KjKl8OWXX16JcQAAANjN7lVLsbGxevbZZ0u0z5gxQ3379i2XQQEAAPuZTGXfHJXdQWbDhg268847S7R369ZNGzZsKJdBAQAA+/GtpVI4ceLEeZdZe3h4KDc3t1wGBQAA7FduX4J2IHbfc9OmTfX++++XaH/vvfcUHh5eLoMCAAD2c8VHS3ZXZJ544gn17t1b+/btU+fOnSVJa9as0cKFC/Xhhx+W+wABAEDpOPIjorKyO8j06NFDS5cu1fTp0/Xhhx/Ky8tLN910k9auXauAgIArMUYAAIDzsjvISFJMTIxiYmIkSbm5uVq0aJHGjx+vtLQ0FRUVlesAAQBA6bhgQabs84I2bNiguLg4hYSE6IUXXlDnzp21adOm8hwbAACwg5up7JujsqsiY7FYNG/ePM2ZM0e5ubnq16+f8vPztXTpUib6AgBQyVxxjkypKzI9evRQWFiYfvzxR7300ks6ePCgXnnllSs5NgAAYAdWLV3EihUr9Mgjj2jEiBFq0KDBlRwTAAAoA0d+RFRWpa7IfP311zp+/LgiIiLUpk0bvfrqqzp8+PCVHBsAAMBFlTrItG3bVm+99ZYOHTqkhx56SO+9955CQkJUXFyslJQUHT9+/EqOEwAAXILpMv7jqOxeteTt7a1hw4bp66+/1vbt2zVu3Dg988wzCgwM1F133XUlxggAAErBFVctXdZnGcLCwjRjxgz98ccfWrRoUXmNCQAAlIErBpkyvRDv79zd3dWrVy/16tWrPE4HAADKwOTIy4/KqFyCDAAAqHyOXFkpK1f84jcAAE6pst4j88wzz8hkMmnMmDHWttOnTys+Pl41a9ZU9erVFRsbq4yMDJvj0tPTFRMTo2rVqikwMFATJkzQmTNn7Lo2QQYAAJTZ1q1b9cYbb6hZs2Y27WPHjtVnn32mxYsXa/369Tp48KB69+5t3V9UVKSYmBgVFBRo48aNmj9/vubNm6dJkybZdX2CDAAATsLNZCrzVhYnTpzQwIED9dZbb6lGjRrW9pycHM2ZM0cvvviiOnfurIiICM2dO1cbN260fpdx1apV2rlzp9555x01b95c3bp101NPPaXXXntNBQUFpb/nMo0cAABcdS5n1VJ+fr5yc3Nttvz8/IteLz4+XjExMYqKirJpT0tLU2FhoU17w4YNVadOHaWmpkqSUlNT1bRpUwUFBVn7REdHKzc3Vzt27Cj9PZe6JwAAuKpdzhyZpKQk+fn52WxJSUkXvNZ7772n77777rx9LBaLPD095e/vb9MeFBQki8Vi7fPXEHNu/7l9pcWqJQAAnITbZbyhNzExUQkJCTZtZrP5vH1///13jR49WikpKapatWqZr1keqMgAAOAkLqciYzab5evra7NdKMikpaUpMzNTLVu2VJUqVVSlShWtX79es2bNUpUqVRQUFKSCggJlZ2fbHJeRkaHg4GBJUnBwcIlVTOd+PtenNAgyAADALl26dNH27du1bds269aqVSsNHDjQ+s8eHh5as2aN9Zjdu3crPT1dkZGRkqTIyEht375dmZmZ1j4pKSny9fVVeHh4qcfCoyUAAJxERb0Qz8fHR02aNLFp8/b2Vs2aNa3tw4cPV0JCggICAuTr66tRo0YpMjJSbdu2lSR17dpV4eHhGjRokGbMmCGLxaLHH39c8fHxF6wEnQ9BBgAAJ1HWZdRXwsyZM+Xm5qbY2Fjl5+crOjpas2fPtu53d3fXsmXLNGLECEVGRsrb21txcXGaOnWqXdcxGYZhlPfgK1vWCfveCgjg/Oo/wMdggfKQs2hQhVznrc2/lfnYB9qEluNIKg4VGQAAnMTVVJGpKAQZAACchAvmGFYtAQAAx0VFBgAAJ+GK1QmCDAAATsLkgs+WCDIAADgJ14sxBBkAAJwGq5YAAIDDcr0Y45rzggAAgJOgIgMAgJNwwSdLBBkAAJwFq5YAAIDDcsX5IgQZAACcBBUZAADgsFwvxhBkAABwGq5YkXHFx2kAAMBJUJEBAMBJuGJ1giADAICTcMVHSwQZAACchOvFGIIMAABOwwULMgQZAACchZsL1mRccV4QAABwElRkAABwEjxaAgAADsvkgo+WCDIAADgJKjIAAMBhueJkX4IMAABOwhUrMqxaAgAADouKDAAATsIVKzIEGQAAnASrlgAAgMNyc70cQ5ABAMBZUJEBAAAOizkyAADAYbliRYbl1wAAwGERZFButn33rR4d83/qGd1Rt0Y01oYv19jsvzWi8Xm3hf9526bfxq/W64HBA9T5lpa6o2OkEhNGVeRtAJWudg0vvRnfTgfe7CfL/Hu08dnuanF9gHW/t7mKnhvSWjtf7S3L/Hu0+bkeGhbVwOYc9QKr652EDtr3Rl/9Pqe/5o2+TbX8qlb0raCCuZnKvtnj9ddfV7NmzeTr6ytfX19FRkZqxYoV1v2nT59WfHy8atasqerVqys2NlYZGRk250hPT1dMTIyqVaumwMBATZgwQWfOnLH7nnm0hHJz6tQp1b8xTDF39da/Jowusf+Tletsft608Ws9M/UJdeh8u7Vt3ZpVevbpJ/VQ/Bi1bN1GRUVntH/v3is9dOCq4e/tqZVT7tBXOyyKfXaNjuTm64ZgH2WfKLD2mT6oldo3DtKDr32j9KwT6twsRC8Mu1mHjp3SirQ/VM1cRUv+GaWffjumHk+nSJL+1be53h/fSV0mrZBhVNbd4UqrqEdL1157rZ555hk1aNBAhmFo/vz56tmzp77//ns1btxYY8eO1fLly7V48WL5+flp5MiR6t27t7755htJUlFRkWJiYhQcHKyNGzfq0KFDGjx4sDw8PDR9+nS7xmIyDOf7n3TWCfsTHcrXrRGNNf35WWrfqcsF+yQmjNLJk3l6OflsRebMmTPq26Orhj8Ur+69YitqqLiI+g8squwhuJzJA1qoTVgtdZuy6oJ9Umf00Mepv+q5Jdutbeun3amUHw7q6Q+2qXPT2vrwsc4Kvf8DHT9VKEny9fLQb//ur7uTVmvdT5Yrfh+wlbNoUIVc5+s9x8p87K0NalzWtQMCAvTcc8+pT58+qlWrlhYuXKg+ffpIknbt2qVGjRopNTVVbdu21YoVK9S9e3cdPHhQQUFBkqTk5GRNnDhRWVlZ8vT0LPV1ebSESnH0yGFt/HqDYnr2trb9smunsjIzZHJz09B7Y9WzaweNG/WQ9u/dU4kjBSpWt4hr9f3+o5o/ur32JvfVV0kxiutc36bPll+ydGfEtapdw0uSdFt4kG6o7au1Px6UJHl6uMswpPzCIusxpwuLVGwYahsWWHE3gwpnuoytrIqKivTee+8pLy9PkZGRSktLU2FhoaKioqx9GjZsqDp16ig1NVWSlJqaqqZNm1pDjCRFR0crNzdXO3bssOv6V3WQ+f333zVs2LDKHgaugBXLPlE172o2j5UO/vmHJOntN15T3PCH9OzLs+Xj46tRDw5Rbk52JY0UqFh1A300POpG7bPkqvczqzUn5Rc9G9da97S/3tpnwrwt2vVnjnbN7qPDCwbqo8e6aPzcLdq4K1OStHVPlvLyz2jKvS3l5emuauYqevq+CFVxd1Owv1dl3RoqgJvJVOYtPz9fubm5Nlt+fv4Fr7V9+3ZVr15dZrNZDz/8sJYsWaLw8HBZLBZ5enrK39/fpn9QUJAslrPVQIvFYhNizu0/t8+ue7ardwU7evSo5s+ff9E+9v7icXVY/skSde3WXWaz2dpWXFwsSRo8/EF17NJVDRs11j8nT5PJZNLa1RcuswPOxM1N+uHXI5r6/jb9+OsxzVu7R/PX7tWwLjda+zwU3VCt61+j/s99qQ7/Wq5/vZOm54ferI5NgiVJR47na8hLG9St5bU6OPce/T6nv/yqeWrb/iMqdr7ZBCgnSUlJ8vPzs9mSkpIu2D8sLEzbtm3T5s2bNWLECMXFxWnnzp0VOOKzKnWy76effnrR/fv377/kOZKSkjRlyhSbtvGJT+jRf066rLHhyvnh+zSl/3ZAU5553qb9mmtqSZLq1rvB2ubp6ana/7hWGZZDFTpGoLJYjp3S7j9ybNp++TNHd91cR5JU1cNdkwY018AX12vV939KknakZ6tZaA2N6h5unf+ydvshNR+zVAE+ZhUVFSvnZKF+eb2Pfk09UbE3hAp1OY+IEhMTlZCQYNP2179s/p2np6fq1z/72DMiIkJbt27Vyy+/rP79+6ugoEDZ2dk2VZmMjAwFB58N28HBwdqyZYvN+c6tajrXp7QqNcj06tVLJpNJF5tvbLrEawrP94vPLXQvl/Hhyli29COFNWqsBjc2tGkPa9RYnp6e+v23X3VTiwhJ0pnCQlkOHVRw7dqVMVSgwm3+JUv1Q3xt2m6o7avfD58NIB5V3ORZxV3Fxbb/3iwqNuR2nn9fHj1+tkLdvnGwavlW1edpf1yhkeOqcBlJxmw2XzS4XEpxcbHy8/MVEREhDw8PrVmzRrGxZxdu7N69W+np6YqMjJQkRUZGatq0acrMzFRg4Nl5WykpKfL19VV4eLhd163UIFO7dm3Nnj1bPXv2PO/+bdu2KSIi4qLnON8vPp9VS5Xi5Mk8/fl7uvXnQwf/0J7dP8vH10/BtUMkSXknTujL1as0cuyEEsd7V6+unrH9NOeN1xQYFKzg2iFa+J+5kqROUdEVcxNAJZv9+c9aNeUOjevZREs2/aaWN9TUkM4NNPrfmyRJx08V6qudFj01MEKnC4r0++E8tWsUqAHtr9e/FqRZzzOwww3a/WeOjuSeVusba+nZwa312oqftfdQbmXdGipARS2/TkxMVLdu3VSnTh0dP35cCxcu1Lp167Ry5Ur5+flp+PDhSkhIUEBAgHx9fTVq1ChFRkaqbdu2kqSuXbsqPDxcgwYN0owZM2SxWPT4448rPj7e7jBVqUEmIiJCaWlpFwwyl6rW4Oqya+cOPfLQUOvPr7w4Q5LUrXtP/WvK2fcCrF71uQzDUFT0nec9R/zo8XJ3r6KnJiUqP/+0wps008vJb8vX1+/K3wBwFfhu/xENfHGdnhzQQo/2bqbfsk4occFWLf7mgLXPsFlf6ckBLfTWyFtVo7qnfs/K01Pvb9Oc1b9Y+zSo7asnB7RQjeqeSs/K0/NLt+u1z3+ujFtCBaqoby1lZmZq8ODBOnTokPz8/NSsWTOtXLlSt99+dgHHzJkz5ebmptjYWOXn5ys6OlqzZ8+2Hu/u7q5ly5ZpxIgRioyMlLe3t+Li4jR16lS7x1Kp75H56quvlJeXpzvuuOO8+/Py8vTtt9+qQ4cOdp2X98gA5YP3yADlo6LeI7N1f86lO11A6+sd8y+MlVqRue222y6639vb2+4QAwAAXAefKAAAwFm43sevCTIAADiLiprsezUhyAAA4CQqarLv1YQgAwCAk3DBHEOQAQDAabhgkrmqv7UEAABwMVRkAABwEkz2BQAADovJvgAAwGG5YI4hyAAA4DRcMMkQZAAAcBLMkQEAAA7LFefIsPwaAAA4LCoyAAA4CRcsyBBkAABwGi6YZAgyAAA4CSb7AgAAh+WKk30JMgAAOAkXzDGsWgIAAI6LigwAAM7CBUsyBBkAAJwEk30BAIDDYrIvAABwWC6YYwgyAAA4DRdMMqxaAgAADouKDAAAToLJvgAAwGEx2RcAADgsF8wxBBkAAJyGCyYZggwAAE6COTIAAMBhueIcGZZfAwAAh0VFBgAAJ+GCBRmCDAAATsMFkwxBBgAAJ+GKk32ZIwMAgJMwmcq+2SMpKUmtW7eWj4+PAgMD1atXL+3evdumz+nTpxUfH6+aNWuqevXqio2NVUZGhk2f9PR0xcTEqFq1agoMDNSECRN05swZu8ZCkAEAwEmYLmOzx/r16xUfH69NmzYpJSVFhYWF6tq1q/Ly8qx9xo4dq88++0yLFy/W+vXrdfDgQfXu3du6v6ioSDExMSooKNDGjRs1f/58zZs3T5MmTbLvng3DMOwc/1Uv64R9aQ7A+dV/YFFlDwFwCjmLBlXIdX4/ml/mY68LMJf52KysLAUGBmr9+vVq3769cnJyVKtWLS1cuFB9+vSRJO3atUuNGjVSamqq2rZtqxUrVqh79+46ePCggoKCJEnJycmaOHGisrKy5OnpWaprU5EBAMBJXM6jpfz8fOXm5tps+fmlC0Y5OTmSpICAAElSWlqaCgsLFRUVZe3TsGFD1alTR6mpqZKk1NRUNW3a1BpiJCk6Olq5ubnasWNHqe+ZIAMAgNMo+8OlpKQk+fn52WxJSUmXvGJxcbHGjBmjdu3aqUmTJpIki8UiT09P+fv72/QNCgqSxWKx9vlriDm3/9y+0mLVEgAATuJy3uybmJiohIQEmzaz+dKPm+Lj4/XTTz/p66+/LvvFLwNBBgAAJ3E5i6/NZnOpgstfjRw5UsuWLdOGDRt07bXXWtuDg4NVUFCg7Oxsm6pMRkaGgoODrX22bNlic75zq5rO9SkNHi0BAOAkKmr5tWEYGjlypJYsWaK1a9eqXr16NvsjIiLk4eGhNWvWWNt2796t9PR0RUZGSpIiIyO1fft2ZWZmWvukpKTI19dX4eHhpR4LFRkAAGCX+Ph4LVy4UJ988ol8fHysc1r8/Pzk5eUlPz8/DR8+XAkJCQoICJCvr69GjRqlyMhItW3bVpLUtWtXhYeHa9CgQZoxY4YsFosef/xxxcfH21UZIsgAAOAkKurNvq+//rokqWPHjjbtc+fO1ZAhQyRJM2fOlJubm2JjY5Wfn6/o6GjNnj3b2tfd3V3Lli3TiBEjFBkZKW9vb8XFxWnq1Kl2jYX3yAC4IN4jA5SPinqPjCW3sMzHBvt6lONIKg4VGQAAnITrfWmJIAMAgNO4nOXXjoogAwCAk+Dr1wAAAA6EigwAAM7C9QoyBBkAAJyFC+YYggwAAM6Cyb4AAMBhueJkX4IMAABOwhUrMqxaAgAADosgAwAAHBaPlgAAcBKu+GiJIAMAgJNgsi8AAHBYVGQAAIDDcsEcQ5ABAMBpuGCSYdUSAABwWFRkAABwEkz2BQAADovJvgAAwGG5YI4hyAAA4DRcMMkQZAAAcBKuOEeGVUsAAMBhUZEBAMBJuOJkX5NhGEZlDwKuJz8/X0lJSUpMTJTZbK7s4QAOiT9HAEEGlSQ3N1d+fn7KycmRr69vZQ8HcEj8OQKYIwMAABwYQQYAADgsggwAAHBYBBlUCrPZrCeffJIJisBl4M8RwGRfAADgwKjIAAAAh0WQAQAADosgAwAAHBZBBhXutddeU926dVW1alW1adNGW7ZsqewhAQ5lw4YN6tGjh0JCQmQymbR06dLKHhJQaQgyqFDvv/++EhIS9OSTT+q7777TTTfdpOjoaGVmZlb20ACHkZeXp5tuukmvvfZaZQ8FqHSsWkKFatOmjVq3bq1XX31VklRcXKzrrrtOo0aN0mOPPVbJowMcj8lk0pIlS9SrV6/KHgpQKajIoMIUFBQoLS1NUVFR1jY3NzdFRUUpNTW1EkcGAHBUBBlUmMOHD6uoqEhBQUE27UFBQbJYLJU0KgCAIyPIAAAAh0WQQYW55ppr5O7uroyMDJv2jIwMBQcHV9KoAACOjCCDCuPp6amIiAitWbPG2lZcXKw1a9YoMjKyEkcGAHBUVSp7AHAtCQkJiouLU6tWrXTzzTfrpZdeUl5enoYOHVrZQwMcxokTJ7R3717rzwcOHNC2bdsUEBCgOnXqVOLIgIrH8mtUuFdffVXPPfecLBaLmjdvrlmzZqlNmzaVPSzAYaxbt06dOnUq0R4XF6d58+ZV/ICASkSQAQAADos5MgAAwGERZAAAgMMiyAAAAIdFkAEAAA6LIAMAABwWQQYAADgsggwAAHBYBBkAAOCwCDIAJElDhgxRr169rD937NhRY8aMqfBxrFu3TiaTSdnZ2RV+bQCOhyADXOWGDBkik8kkk8kkT09P1a9fX1OnTtWZM2eu6HU//vhjPfXUU6XqS/gAUFn4aCTgAO644w7NnTtX+fn5+vzzzxUfHy8PDw8lJiba9CsoKJCnp2e5XDMgIKBczgMAVxIVGcABmM1mBQcHKzQ0VCNGjFBUVJQ+/fRT6+OgadOmKSQkRGFhYZKk33//Xf369ZO/v78CAgLUs2dP/frrr9bzFRUVKSEhQf7+/qpZs6YeffRR/f2za39/tJSfn6+JEyfquuuuk9lsVv369TVnzhz9+uuv1g8Y1qhRQyaTSUOGDJEkFRcXKykpSfXq1ZOXl5duuukmffjhhzbX+fzzz3XjjTfKy8tLnTp1shknAFwKQQZwQF5eXiooKJAkrVmzRrt371ZKSoqWLVumwsJCRUdHy8fHR1999ZW++eYbVa9eXXfccYf1mBdeeEHz5s3T22+/ra+//lpHjx7VkiVLLnrNwYMHa9GiRZo1a5Z+/vlnvfHGG6pevbquu+46ffTRR5Kk3bt369ChQ3r55ZclSUlJSfrPf/6j5ORk7dixQ2PHjtV9992n9evXSzobuHr37q0ePXpo27Ztuv/++/XYY49dqV8bAGdkALiqxcXFGT179jQMwzCKi4uNlJQUw2w2G+PHjzfi4uKMoKAgIz8/39p/wYIFRlhYmFFcXGxty8/PN7y8vIyVK1cahmEYtWvXNmbMmGHdX1hYaFx77bXW6xiGYXTo0MEYPXq0YRiGsXv3bkOSkZKSct4xfvnll4Yk49ixY9a206dPG9WqVTM2btxo03f48OHGPffcYxiGYSQmJhrh4eE2+ydOnFjiXABwIcyRARzAsmXLVL16dRUWFqq4uFj33nuvJk+erPj4eDVt2tRmXswPP/ygvXv3ysfHx+Ycp0+f1r59+5STk6NDhw6pTZs21n1VqlRRq1atSjxeOmfbtm1yd3dXhw4dSj3mvXv36uTJk7r99ttt2gsKCtSiRQtJ0s8//2wzDkmKjIws9TUAgCADOIBOnTrp9ddfl6enp0JCQlSlyv/+6Hp7e9v0PXHihCIiIvTuu++WOE+tWrXKdH0vLy+7jzlx4oQkafny5frHP/5hs89sNpdpHADwdwQZwAF4e3urfv36perbsmVLvf/++woMDJSvr+95+9SuXVubN29W+/btJUlnzpxRWlqaWrZsed7+TZs2VXFxsdavX6+oqKgS+89VhIqKiqxt4eHhMpvNSk9Pv2Alp1GjRvr0009t2jZt2nTpmwSA/2KyL+BkBg4cqGuuuUY9e/bUV199pQMHDmjdunV65JFH9Mcff0iSRo8erWeeeUZLly7Vrl279H//938XfQdM3bp1FRcXp2HDhmnp0qXWc37wwQeSpNDQUJlMJi1btkxZWVk6ceKEfHx8NH78eI0dO1bz58/Xvn379N133+mVV17R/PnzJUkPP/yw9uzZowkTJmj37t1auHCh5s2bd6V/RQCcCEEGcDLVqlXThg0bVKdOHfXu3VuNGjXS8OHDdfr0aWuFZty4cRo0aJDi4uIUGRkpHx8f3X333Rc97+uvv64+ffro//7v/9SwYUM98MADysvLkyT94x//0JQpU/TYY48pKChII0eOlCQ99dRTeuKJJ5SUlKRGjRrpjjvu0PLly1WvXj1JUp06dfTRRx9p6dKluummm5ScnKzp06dfwd8OAGdjMi40uw8AAOAqR0UGAAA4LIIMAABwWAQZAADgsAgyAADAYRFkAACAwyLIAAAAh0WQAQAADosgAwAAHBZBBgAAOCyCDAAAcFgEGQAA4LAIMgAAwGH9P3MQCtM9YeOHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(confusion_matrix(y_true, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuXlOb8LuvTX"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_filters1 = [8,16]\n",
        "n_filters2 = [16,32]\n",
        "fc_size = [32,64]\n",
        "lr = [1e-3,5e-4]\n",
        "\n",
        "class CNN1D(nn.Module):\n",
        "    def __init__(self, n_filters1, n_filters2, fc_size):\n",
        "        super(CNN1D, self).__init__()\n",
        "        self.conv1 = nn.Conv1d(1, n_filters1, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool1d(2)\n",
        "        self.conv2 = nn.Conv1d(n_filters1, n_filters2, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(n_filters2 * 3, fc_size)\n",
        "        self.fc2 = nn.Linear(fc_size, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)  # raw logits\n",
        "        return x\n",
        "\n",
        "\n",
        "max_accuracy = 0.0\n",
        "best_params = {\"n_filters1\" : 0.0, \"n_filters2\" :0.0, \"fc_size\" : 0.0, \"lr\" : 0.0}\n",
        "\n",
        "\n",
        "for i in range(len(n_filters1)):\n",
        "    for j in range(len(n_filters2)):\n",
        "          for l in range(len(fc_size)):\n",
        "              for m in range(len(lr)):\n",
        "                  model = CNN1D(n_filters1[i], n_filters2[j], fc_size[l])\n",
        "                  criterion = nn.BCEWithLogitsLoss()\n",
        "                  optimizer = torch.optim.Adam(model.parameters(), lr=lr[m])\n",
        "\n",
        "                  for epoch in range(1, 21):\n",
        "                    model.train()\n",
        "                    total_loss = 0.0\n",
        "                    for batch_X, batch_y in train_loader:\n",
        "\n",
        "\n",
        "                        optimizer.zero_grad()\n",
        "                        outputs = model(batch_X).squeeze()\n",
        "\n",
        "\n",
        "                        if torch.isnan(outputs).any():\n",
        "\n",
        "                            continue\n",
        "\n",
        "                        loss = criterion(outputs, batch_y)\n",
        "                        loss.backward()\n",
        "\n",
        "                        # Gradient clipping\n",
        "                        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "                        optimizer.step()\n",
        "                        total_loss += loss.item()\n",
        "\n",
        "                    print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "                  model.eval()\n",
        "\n",
        "                  with torch.no_grad():\n",
        "                      logits = model(X_test).squeeze()\n",
        "                      probs = torch.sigmoid(logits)\n",
        "                      preds = (probs > 0.5).float()\n",
        "                      accuracy = (preds == y_test).float().mean()\n",
        "                      print(f\"‚úÖ Test Accuracy: {accuracy:.4f}\")\n",
        "                  if accuracy > max_accuracy:\n",
        "                      max_accuracy = accuracy\n",
        "                      best_params[\"n_filters1\"] = n_filters1[i]\n",
        "                      best_params[\"n_filters2\"] = n_filters2[j]\n",
        "                      best_params[\"fc_size\"] = fc_size[l]\n",
        "                      best_params[\"lr\"] = lr[m]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZ6hms545_tU",
        "outputId": "2ff07003-f716-498f-bc5b-260df2b419f8"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 123.1372\n",
            "Epoch 2, Loss: 110.0344\n",
            "Epoch 3, Loss: 106.4722\n",
            "Epoch 4, Loss: 102.1245\n",
            "Epoch 5, Loss: 98.6579\n",
            "Epoch 6, Loss: 96.3776\n",
            "Epoch 7, Loss: 94.5270\n",
            "Epoch 8, Loss: 93.1400\n",
            "Epoch 9, Loss: 91.0959\n",
            "Epoch 10, Loss: 90.3861\n",
            "Epoch 11, Loss: 89.3952\n",
            "Epoch 12, Loss: 88.6312\n",
            "Epoch 13, Loss: 88.3501\n",
            "Epoch 14, Loss: 86.9637\n",
            "Epoch 15, Loss: 86.2475\n",
            "Epoch 16, Loss: 86.0176\n",
            "Epoch 17, Loss: 85.6224\n",
            "Epoch 18, Loss: 84.3820\n",
            "Epoch 19, Loss: 83.5627\n",
            "Epoch 20, Loss: 84.0374\n",
            "‚úÖ Test Accuracy: 0.8228\n",
            "Epoch 1, Loss: 134.7803\n",
            "Epoch 2, Loss: 113.7653\n",
            "Epoch 3, Loss: 110.8774\n",
            "Epoch 4, Loss: 107.8731\n",
            "Epoch 5, Loss: 105.4149\n",
            "Epoch 6, Loss: 103.8643\n",
            "Epoch 7, Loss: 101.7128\n",
            "Epoch 8, Loss: 99.9426\n",
            "Epoch 9, Loss: 98.1193\n",
            "Epoch 10, Loss: 95.9822\n",
            "Epoch 11, Loss: 94.5632\n",
            "Epoch 12, Loss: 93.6891\n",
            "Epoch 13, Loss: 92.4882\n",
            "Epoch 14, Loss: 92.2337\n",
            "Epoch 15, Loss: 90.9951\n",
            "Epoch 16, Loss: 89.9172\n",
            "Epoch 17, Loss: 89.7610\n",
            "Epoch 18, Loss: 88.8281\n",
            "Epoch 19, Loss: 88.7205\n",
            "Epoch 20, Loss: 88.2225\n",
            "‚úÖ Test Accuracy: 0.8032\n",
            "Epoch 1, Loss: 123.3899\n",
            "Epoch 2, Loss: 111.9809\n",
            "Epoch 3, Loss: 107.7545\n",
            "Epoch 4, Loss: 103.0295\n",
            "Epoch 5, Loss: 99.5029\n",
            "Epoch 6, Loss: 96.3430\n",
            "Epoch 7, Loss: 93.6726\n",
            "Epoch 8, Loss: 90.5675\n",
            "Epoch 9, Loss: 90.1124\n",
            "Epoch 10, Loss: 87.7269\n",
            "Epoch 11, Loss: 87.4399\n",
            "Epoch 12, Loss: 86.4090\n",
            "Epoch 13, Loss: 86.0363\n",
            "Epoch 14, Loss: 84.3988\n",
            "Epoch 15, Loss: 83.4462\n",
            "Epoch 16, Loss: 84.7532\n",
            "Epoch 17, Loss: 83.0483\n",
            "Epoch 18, Loss: 82.2294\n",
            "Epoch 19, Loss: 81.8902\n",
            "Epoch 20, Loss: 80.9127\n",
            "‚úÖ Test Accuracy: 0.8111\n",
            "Epoch 1, Loss: 129.7758\n",
            "Epoch 2, Loss: 112.9056\n",
            "Epoch 3, Loss: 109.8047\n",
            "Epoch 4, Loss: 107.2643\n",
            "Epoch 5, Loss: 104.7109\n",
            "Epoch 6, Loss: 102.2572\n",
            "Epoch 7, Loss: 100.7925\n",
            "Epoch 8, Loss: 98.5897\n",
            "Epoch 9, Loss: 96.1592\n",
            "Epoch 10, Loss: 94.4543\n",
            "Epoch 11, Loss: 93.2309\n",
            "Epoch 12, Loss: 91.7328\n",
            "Epoch 13, Loss: 90.0974\n",
            "Epoch 14, Loss: 89.7931\n",
            "Epoch 15, Loss: 88.3551\n",
            "Epoch 16, Loss: 88.2989\n",
            "Epoch 17, Loss: 87.7772\n",
            "Epoch 18, Loss: 86.7903\n",
            "Epoch 19, Loss: 85.6749\n",
            "Epoch 20, Loss: 84.6887\n",
            "‚úÖ Test Accuracy: 0.8066\n",
            "Epoch 1, Loss: 123.4500\n",
            "Epoch 2, Loss: 109.9252\n",
            "Epoch 3, Loss: 104.7802\n",
            "Epoch 4, Loss: 100.4202\n",
            "Epoch 5, Loss: 97.8415\n",
            "Epoch 6, Loss: 94.0392\n",
            "Epoch 7, Loss: 92.1438\n",
            "Epoch 8, Loss: 90.9752\n",
            "Epoch 9, Loss: 87.9227\n",
            "Epoch 10, Loss: 86.8801\n",
            "Epoch 11, Loss: 87.5419\n",
            "Epoch 12, Loss: 85.3897\n",
            "Epoch 13, Loss: 85.1635\n",
            "Epoch 14, Loss: 84.6729\n",
            "Epoch 15, Loss: 83.4805\n",
            "Epoch 16, Loss: 82.7562\n",
            "Epoch 17, Loss: 82.4032\n",
            "Epoch 18, Loss: 83.4614\n",
            "Epoch 19, Loss: 82.4415\n",
            "Epoch 20, Loss: 81.4646\n",
            "‚úÖ Test Accuracy: 0.8267\n",
            "Epoch 1, Loss: 130.5597\n",
            "Epoch 2, Loss: 115.2122\n",
            "Epoch 3, Loss: 111.3263\n",
            "Epoch 4, Loss: 108.3670\n",
            "Epoch 5, Loss: 106.5028\n",
            "Epoch 6, Loss: 104.0174\n",
            "Epoch 7, Loss: 101.8961\n",
            "Epoch 8, Loss: 100.2635\n",
            "Epoch 9, Loss: 98.5895\n",
            "Epoch 10, Loss: 96.8327\n",
            "Epoch 11, Loss: 94.8329\n",
            "Epoch 12, Loss: 93.3725\n",
            "Epoch 13, Loss: 91.7012\n",
            "Epoch 14, Loss: 90.2252\n",
            "Epoch 15, Loss: 88.9064\n",
            "Epoch 16, Loss: 88.2445\n",
            "Epoch 17, Loss: 86.8005\n",
            "Epoch 18, Loss: 86.3941\n",
            "Epoch 19, Loss: 86.0569\n",
            "Epoch 20, Loss: 84.1715\n",
            "‚úÖ Test Accuracy: 0.8200\n",
            "Epoch 1, Loss: 122.0997\n",
            "Epoch 2, Loss: 107.8695\n",
            "Epoch 3, Loss: 101.5433\n",
            "Epoch 4, Loss: 95.5132\n",
            "Epoch 5, Loss: 91.9341\n",
            "Epoch 6, Loss: 89.7846\n",
            "Epoch 7, Loss: 87.8449\n",
            "Epoch 8, Loss: 86.8656\n",
            "Epoch 9, Loss: 84.8690\n",
            "Epoch 10, Loss: 83.9833\n",
            "Epoch 11, Loss: 83.8251\n",
            "Epoch 12, Loss: 83.4387\n",
            "Epoch 13, Loss: 82.8565\n",
            "Epoch 14, Loss: 81.5840\n",
            "Epoch 15, Loss: 81.9327\n",
            "Epoch 16, Loss: 79.8669\n",
            "Epoch 17, Loss: 79.6106\n",
            "Epoch 18, Loss: 79.7694\n",
            "Epoch 19, Loss: 79.6364\n",
            "Epoch 20, Loss: 78.3323\n",
            "‚úÖ Test Accuracy: 0.8122\n",
            "Epoch 1, Loss: 125.2407\n",
            "Epoch 2, Loss: 116.3976\n",
            "Epoch 3, Loss: 114.5189\n",
            "Epoch 4, Loss: 112.4639\n",
            "Epoch 5, Loss: 109.8750\n",
            "Epoch 6, Loss: 107.8233\n",
            "Epoch 7, Loss: 105.1917\n",
            "Epoch 8, Loss: 102.2500\n",
            "Epoch 9, Loss: 100.0384\n",
            "Epoch 10, Loss: 97.7328\n",
            "Epoch 11, Loss: 96.6194\n",
            "Epoch 12, Loss: 94.3367\n",
            "Epoch 13, Loss: 92.9989\n",
            "Epoch 14, Loss: 91.9174\n",
            "Epoch 15, Loss: 90.9055\n",
            "Epoch 16, Loss: 89.1745\n",
            "Epoch 17, Loss: 88.8894\n",
            "Epoch 18, Loss: 87.1455\n",
            "Epoch 19, Loss: 86.7429\n",
            "Epoch 20, Loss: 86.5128\n",
            "‚úÖ Test Accuracy: 0.8055\n",
            "Epoch 1, Loss: 122.8811\n",
            "Epoch 2, Loss: 111.3364\n",
            "Epoch 3, Loss: 105.2368\n",
            "Epoch 4, Loss: 100.1773\n",
            "Epoch 5, Loss: 95.1920\n",
            "Epoch 6, Loss: 92.5244\n",
            "Epoch 7, Loss: 90.2702\n",
            "Epoch 8, Loss: 88.9042\n",
            "Epoch 9, Loss: 87.8176\n",
            "Epoch 10, Loss: 87.0403\n",
            "Epoch 11, Loss: 85.7607\n",
            "Epoch 12, Loss: 85.3188\n",
            "Epoch 13, Loss: 83.9944\n",
            "Epoch 14, Loss: 84.4057\n",
            "Epoch 15, Loss: 83.5175\n",
            "Epoch 16, Loss: 82.8257\n",
            "Epoch 17, Loss: 81.6441\n",
            "Epoch 18, Loss: 80.8709\n",
            "Epoch 19, Loss: 80.8130\n",
            "Epoch 20, Loss: 81.9223\n",
            "‚úÖ Test Accuracy: 0.8099\n",
            "Epoch 1, Loss: 132.5323\n",
            "Epoch 2, Loss: 113.9566\n",
            "Epoch 3, Loss: 110.5286\n",
            "Epoch 4, Loss: 106.8164\n",
            "Epoch 5, Loss: 103.9799\n",
            "Epoch 6, Loss: 101.4947\n",
            "Epoch 7, Loss: 98.8398\n",
            "Epoch 8, Loss: 96.8621\n",
            "Epoch 9, Loss: 95.0984\n",
            "Epoch 10, Loss: 93.7611\n",
            "Epoch 11, Loss: 92.1622\n",
            "Epoch 12, Loss: 91.0841\n",
            "Epoch 13, Loss: 90.1276\n",
            "Epoch 14, Loss: 89.0602\n",
            "Epoch 15, Loss: 88.2666\n",
            "Epoch 16, Loss: 87.4332\n",
            "Epoch 17, Loss: 88.0681\n",
            "Epoch 18, Loss: 86.9944\n",
            "Epoch 19, Loss: 85.4536\n",
            "Epoch 20, Loss: 84.7794\n",
            "‚úÖ Test Accuracy: 0.8044\n",
            "Epoch 1, Loss: 121.2804\n",
            "Epoch 2, Loss: 107.3187\n",
            "Epoch 3, Loss: 97.4853\n",
            "Epoch 4, Loss: 94.4727\n",
            "Epoch 5, Loss: 90.8549\n",
            "Epoch 6, Loss: 88.4052\n",
            "Epoch 7, Loss: 86.2254\n",
            "Epoch 8, Loss: 85.7245\n",
            "Epoch 9, Loss: 83.8125\n",
            "Epoch 10, Loss: 84.0710\n",
            "Epoch 11, Loss: 81.8844\n",
            "Epoch 12, Loss: 80.9156\n",
            "Epoch 13, Loss: 80.6223\n",
            "Epoch 14, Loss: 80.6409\n",
            "Epoch 15, Loss: 80.5245\n",
            "Epoch 16, Loss: 79.8803\n",
            "Epoch 17, Loss: 78.8743\n",
            "Epoch 18, Loss: 79.7155\n",
            "Epoch 19, Loss: 78.8452\n",
            "Epoch 20, Loss: 77.7284\n",
            "‚úÖ Test Accuracy: 0.8228\n",
            "Epoch 1, Loss: 128.4754\n",
            "Epoch 2, Loss: 111.1419\n",
            "Epoch 3, Loss: 106.0945\n",
            "Epoch 4, Loss: 102.3370\n",
            "Epoch 5, Loss: 100.0255\n",
            "Epoch 6, Loss: 97.2303\n",
            "Epoch 7, Loss: 95.5898\n",
            "Epoch 8, Loss: 94.0199\n",
            "Epoch 9, Loss: 92.3145\n",
            "Epoch 10, Loss: 92.1525\n",
            "Epoch 11, Loss: 90.4641\n",
            "Epoch 12, Loss: 89.5223\n",
            "Epoch 13, Loss: 88.8030\n",
            "Epoch 14, Loss: 88.4239\n",
            "Epoch 15, Loss: 88.0784\n",
            "Epoch 16, Loss: 87.4953\n",
            "Epoch 17, Loss: 86.1541\n",
            "Epoch 18, Loss: 86.3188\n",
            "Epoch 19, Loss: 85.5911\n",
            "Epoch 20, Loss: 84.6890\n",
            "‚úÖ Test Accuracy: 0.8127\n",
            "Epoch 1, Loss: 122.4645\n",
            "Epoch 2, Loss: 106.3132\n",
            "Epoch 3, Loss: 99.7949\n",
            "Epoch 4, Loss: 95.5747\n",
            "Epoch 5, Loss: 91.3533\n",
            "Epoch 6, Loss: 89.1447\n",
            "Epoch 7, Loss: 88.2200\n",
            "Epoch 8, Loss: 87.1330\n",
            "Epoch 9, Loss: 84.4335\n",
            "Epoch 10, Loss: 84.0199\n",
            "Epoch 11, Loss: 82.2696\n",
            "Epoch 12, Loss: 81.5763\n",
            "Epoch 13, Loss: 81.5050\n",
            "Epoch 14, Loss: 80.7579\n",
            "Epoch 15, Loss: 80.5602\n",
            "Epoch 16, Loss: 79.0944\n",
            "Epoch 17, Loss: 79.7609\n",
            "Epoch 18, Loss: 78.7955\n",
            "Epoch 19, Loss: 78.6599\n",
            "Epoch 20, Loss: 78.4489\n",
            "‚úÖ Test Accuracy: 0.8161\n",
            "Epoch 1, Loss: 127.9190\n",
            "Epoch 2, Loss: 109.0103\n",
            "Epoch 3, Loss: 102.7799\n",
            "Epoch 4, Loss: 98.3931\n",
            "Epoch 5, Loss: 95.2374\n",
            "Epoch 6, Loss: 92.7119\n",
            "Epoch 7, Loss: 90.4825\n",
            "Epoch 8, Loss: 88.5496\n",
            "Epoch 9, Loss: 86.9007\n",
            "Epoch 10, Loss: 86.5377\n",
            "Epoch 11, Loss: 84.2265\n",
            "Epoch 12, Loss: 83.7643\n",
            "Epoch 13, Loss: 82.1176\n",
            "Epoch 14, Loss: 81.1922\n",
            "Epoch 15, Loss: 81.0180\n",
            "Epoch 16, Loss: 80.5091\n",
            "Epoch 17, Loss: 80.3611\n",
            "Epoch 18, Loss: 80.0874\n",
            "Epoch 19, Loss: 79.0973\n",
            "Epoch 20, Loss: 79.4261\n",
            "‚úÖ Test Accuracy: 0.8217\n",
            "Epoch 1, Loss: 118.0434\n",
            "Epoch 2, Loss: 102.2870\n",
            "Epoch 3, Loss: 95.7365\n",
            "Epoch 4, Loss: 92.1137\n",
            "Epoch 5, Loss: 87.2592\n",
            "Epoch 6, Loss: 86.1891\n",
            "Epoch 7, Loss: 84.2445\n",
            "Epoch 8, Loss: 84.4924\n",
            "Epoch 9, Loss: 81.9887\n",
            "Epoch 10, Loss: 83.0419\n",
            "Epoch 11, Loss: 81.4904\n",
            "Epoch 12, Loss: 79.5254\n",
            "Epoch 13, Loss: 79.4922\n",
            "Epoch 14, Loss: 79.0433\n",
            "Epoch 15, Loss: 78.5639\n",
            "Epoch 16, Loss: 77.7628\n",
            "Epoch 17, Loss: 76.9771\n",
            "Epoch 18, Loss: 76.0598\n",
            "Epoch 19, Loss: 76.3930\n",
            "Epoch 20, Loss: 76.3544\n",
            "‚úÖ Test Accuracy: 0.8139\n",
            "Epoch 1, Loss: 123.1016\n",
            "Epoch 2, Loss: 106.9556\n",
            "Epoch 3, Loss: 101.1135\n",
            "Epoch 4, Loss: 96.8219\n",
            "Epoch 5, Loss: 93.7801\n",
            "Epoch 6, Loss: 90.8158\n",
            "Epoch 7, Loss: 89.1383\n",
            "Epoch 8, Loss: 87.1206\n",
            "Epoch 9, Loss: 86.2503\n",
            "Epoch 10, Loss: 85.1301\n",
            "Epoch 11, Loss: 84.2508\n",
            "Epoch 12, Loss: 83.0062\n",
            "Epoch 13, Loss: 83.0516\n",
            "Epoch 14, Loss: 81.6772\n",
            "Epoch 15, Loss: 81.7235\n",
            "Epoch 16, Loss: 80.7307\n",
            "Epoch 17, Loss: 80.3415\n",
            "Epoch 18, Loss: 79.6082\n",
            "Epoch 19, Loss: 79.1835\n",
            "Epoch 20, Loss: 78.7479\n",
            "‚úÖ Test Accuracy: 0.8189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"max accuracy\" , max_accuracy)\n",
        "print(\"best params\" , best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJq-fesO7UIc",
        "outputId": "48652b1e-d578-4367-b700-ee2f715d1b8e"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max accuracy tensor(0.8267)\n",
            "best params {'n_filters1': 8, 'n_filters2': 32, 'fc_size': 32, 'lr': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBCwiFOGtyW2"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_drT25SCOezb",
        "outputId": "de031c85-06da-438c-a946-3cb804f1a867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 123.5867\n",
            "Epoch 2, Loss: 111.2213\n",
            "Epoch 3, Loss: 97.9465\n",
            "Epoch 4, Loss: 94.5952\n",
            "Epoch 5, Loss: 93.3551\n",
            "Epoch 6, Loss: 92.4203\n",
            "Epoch 7, Loss: 91.4145\n",
            "Epoch 8, Loss: 89.7251\n",
            "Epoch 9, Loss: 88.8953\n",
            "Epoch 10, Loss: 88.3125\n",
            "Epoch 11, Loss: 88.2870\n",
            "Epoch 12, Loss: 86.7667\n",
            "Epoch 13, Loss: 86.0222\n",
            "Epoch 14, Loss: 85.4742\n",
            "Epoch 15, Loss: 84.0956\n",
            "Epoch 16, Loss: 83.8745\n",
            "Epoch 17, Loss: 83.3542\n",
            "Epoch 18, Loss: 82.3154\n",
            "Epoch 19, Loss: 81.4166\n",
            "Epoch 20, Loss: 80.7380\n",
            "Epoch 21, Loss: 78.6329\n",
            "Epoch 22, Loss: 78.8809\n",
            "Epoch 23, Loss: 77.7690\n",
            "Epoch 24, Loss: 77.3297\n",
            "Epoch 25, Loss: 76.7742\n",
            "Epoch 26, Loss: 76.0088\n",
            "Epoch 27, Loss: 75.6613\n",
            "Epoch 28, Loss: 74.9386\n",
            "Epoch 29, Loss: 74.9629\n",
            "Epoch 30, Loss: 74.4753\n",
            "Epoch 31, Loss: 73.9668\n",
            "Epoch 32, Loss: 73.2291\n",
            "Epoch 33, Loss: 72.8602\n",
            "Epoch 34, Loss: 71.9842\n",
            "Epoch 35, Loss: 71.4710\n",
            "Epoch 36, Loss: 70.8271\n",
            "Epoch 37, Loss: 70.3530\n",
            "Epoch 38, Loss: 69.6431\n",
            "Epoch 39, Loss: 68.3121\n",
            "Epoch 40, Loss: 67.2516\n",
            "Epoch 41, Loss: 66.9373\n",
            "Epoch 42, Loss: 66.2163\n",
            "Epoch 43, Loss: 64.9768\n",
            "Epoch 44, Loss: 64.2336\n",
            "Epoch 45, Loss: 62.9567\n",
            "Epoch 46, Loss: 61.8525\n",
            "Epoch 47, Loss: 60.3189\n",
            "Epoch 48, Loss: 59.8007\n",
            "Epoch 49, Loss: 58.7332\n",
            "üìä LSTM Test Accuracy: 0.8295\n"
          ]
        }
      ],
      "source": [
        "X = df[target_column]\n",
        "y = df['team_win']\n",
        "\n",
        "# Normalize input\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Convert to tensors\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32).unsqueeze(2)  # shape: (batch, 14, 1)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.float32)\n",
        "\n",
        "# Ensure binary target\n",
        "y_tensor = (y_tensor > 0.5).float()\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=32)\n",
        "\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=1, hidden_dim=64, num_layers=1):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_out, _ = self.lstm(x)               # lstm_out: (batch, seq_len, hidden_dim)\n",
        "        last_output = lstm_out[:, -1, :]         # get last time step output\n",
        "        output = self.fc(last_output)            # shape: (batch, 1)\n",
        "        return output                            # raw logits\n",
        "\n",
        "# ----------- Training -----------\n",
        "\n",
        "model = LSTMClassifier()\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1, 50):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X).squeeze()\n",
        "\n",
        "        if torch.isnan(outputs).any():\n",
        "            #print(\"‚ö†Ô∏è NaNs detected in output!\")\n",
        "            continue\n",
        "\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n",
        "\n",
        "# ----------- Evaluation -----------\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    logits = model(X_test).squeeze()\n",
        "    probs = torch.sigmoid(logits)\n",
        "    preds = (probs > 0.5).float()\n",
        "    accuracy = (preds == y_test).float().mean()\n",
        "    print(f\"üìä LSTM Test Accuracy: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaC6W05TkhitgBOAukNjxm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}